{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "See file costs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(e):\n",
    "    return 1/(2*len(e)) * np.dot(e, e)\n",
    "\n",
    "def mae(e):\n",
    "    return 1/(2*len(e)) * np.sum(np.abs(e))\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: shape=(N, )\n",
    "        tx: shape=(N,2)\n",
    "        w: shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    e = tx @ w - y\n",
    "    return mse(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costs import compute_loss\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for row, w0 in enumerate(grid_w0):\n",
    "        for col, w1 in enumerate(grid_w1):\n",
    "            losses[row, col] = compute_loss(y, tx, np.array([w0, w1]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=18.79354101952324, w0*=71.42857142857142, w1*=15.306122448979579, execution time=0.279 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters, grid_search\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad for 100 + 20x: [26.706078    6.52028757]\n",
      "grad for 50 + 10x: [-23.293922    -3.47971243]\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    e = y - tx @ w\n",
    "    return - 1/len(e) * tx.T @ e\n",
    "\n",
    "print(f\"grad for 100 + 20x: {compute_gradient(y, tx, [100, 20])}\") ## 100 and 20 should be smaller\n",
    "print(f\"grad for 50 + 10x: {compute_gradient(y, tx, [50, 10])}\") ## 50 and 10 should be bigger (10 slightly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        w = w - gamma * grad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.236712759168, w0=7.329392200210518, w1=1.347971243498896\n",
      "GD iter. 1/49: loss=2264.6350560300034, w0=13.925845180399984, w1=2.5611453626479044\n",
      "GD iter. 2/49: loss=1837.2777140793805, w0=19.862652862570506, w1=3.653002069882011\n",
      "GD iter. 3/49: loss=1491.1182670993753, w0=25.205779776523975, w1=4.63567310639271\n",
      "GD iter. 4/49: loss=1210.7291150455717, w0=30.014593999082095, w1=5.520077039252341\n",
      "GD iter. 5/49: loss=983.6139018819908, w0=34.3425267993844, w1=6.316040578826008\n",
      "GD iter. 6/49: loss=799.6505792194903, w0=38.23766631965648, w1=7.032407764442307\n",
      "GD iter. 7/49: loss=650.6402878628647, w0=41.74329188790136, w1=7.677138231496977\n",
      "GD iter. 8/49: loss=529.9419518639978, w0=44.89835489932174, w1=8.257395651846181\n",
      "GD iter. 9/49: loss=432.17629970491606, w0=47.73791160960008, w1=8.779627330160464\n",
      "GD iter. 10/49: loss=352.9861214560596, w0=50.293512648850594, w1=9.24963584064332\n",
      "GD iter. 11/49: loss=288.84207707448587, w0=52.59355358417605, w1=9.67264350007789\n",
      "GD iter. 12/49: loss=236.8854011254112, w0=54.66359042596896, w1=10.053350393569003\n",
      "GD iter. 13/49: loss=194.80049360666067, w0=56.526623583582584, w1=10.395986597711007\n",
      "GD iter. 14/49: loss=160.71171851647276, w0=58.20335342543484, w1=10.704359181438809\n",
      "GD iter. 15/49: loss=133.0998106934206, w0=59.712410283101875, w1=10.98189450679383\n",
      "GD iter. 16/49: loss=110.73416535674828, w0=61.070561455002206, w1=11.231676299613351\n",
      "GD iter. 17/49: loss=92.61799263404369, w0=62.2928975097125, w1=11.45647991315092\n",
      "GD iter. 18/49: loss=77.943892728653, w0=63.39299995895177, w1=11.658803165334731\n",
      "GD iter. 19/49: loss=66.05787180528654, w0=64.38309216326711, w1=11.840894092300163\n",
      "GD iter. 20/49: loss=56.430194857359716, w0=65.27417514715091, w1=12.00477592656905\n",
      "GD iter. 21/49: loss=48.631776529538975, w0=66.07614983264634, w1=12.15226957741105\n",
      "GD iter. 22/49: loss=42.31505768400419, w0=66.79792704959222, w1=12.285013863168848\n",
      "GD iter. 23/49: loss=37.19851541912101, w0=67.44752654484351, w1=12.404483720350868\n",
      "GD iter. 24/49: loss=33.05411618456562, w0=68.03216609056967, w1=12.512006591814686\n",
      "GD iter. 25/49: loss=29.69715280457577, w0=68.55834168172322, w1=12.608777176132122\n",
      "GD iter. 26/49: loss=26.978012466783987, w0=69.03189971376142, w1=12.695870702017814\n",
      "GD iter. 27/49: loss=24.77550879317261, w0=69.45810194259579, w1=12.774254875314936\n",
      "GD iter. 28/49: loss=22.991480817547423, w0=69.84168394854673, w1=12.844800631282347\n",
      "GD iter. 29/49: loss=21.546418157290994, w0=70.18690775390257, w1=12.908291811653017\n",
      "GD iter. 30/49: loss=20.375917402483303, w0=70.49760917872284, w1=12.965433873986619\n",
      "GD iter. 31/49: loss=19.42781179108905, w0=70.77724046106107, w1=13.016861730086863\n",
      "GD iter. 32/49: loss=18.659846245859733, w0=71.02890861516548, w1=13.063146800577082\n",
      "GD iter. 33/49: loss=18.037794154223974, w0=71.25540995385944, w1=13.104803364018277\n",
      "GD iter. 34/49: loss=17.53393195999902, w0=71.45926115868401, w1=13.142294271115354\n",
      "GD iter. 35/49: loss=17.1258035826768, w0=71.64272724302613, w1=13.176036087502723\n",
      "GD iter. 36/49: loss=16.795219597045797, w0=71.80784671893403, w1=13.206403722251356\n",
      "GD iter. 37/49: loss=16.527446568684688, w0=71.95645424725114, w1=13.233734593525124\n",
      "GD iter. 38/49: loss=16.310550415712186, w0=72.09020102273655, w1=13.258332377671517\n",
      "GD iter. 39/49: loss=16.134864531804453, w0=72.21057312067342, w1=13.28047038340327\n",
      "GD iter. 40/49: loss=15.992558965839196, w0=72.31890800881659, w1=13.300394588561847\n",
      "GD iter. 41/49: loss=15.877291457407335, w0=72.41640940814546, w1=13.318326373204567\n",
      "GD iter. 42/49: loss=15.783924775577523, w0=72.50416066754143, w1=13.334464979383014\n",
      "GD iter. 43/49: loss=15.708297763295382, w0=72.5831368009978, w1=13.348989724943618\n",
      "GD iter. 44/49: loss=15.647039883346842, w0=72.65421532110854, w1=13.36206199594816\n",
      "GD iter. 45/49: loss=15.597421000588533, w0=72.71818598920821, w1=13.373827039852248\n",
      "GD iter. 46/49: loss=15.557229705554294, w0=72.77575959049791, w1=13.384415579365928\n",
      "GD iter. 47/49: loss=15.52467475657656, w0=72.82757583165863, w1=13.39394526492824\n",
      "GD iter. 48/49: loss=15.498305247904602, w0=72.8742104487033, w1=13.40252198193432\n",
      "GD iter. 49/49: loss=15.476945945880313, w0=72.91618160404349, w1=13.410241027239794\n",
      "GD: execution time=0.025 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0940c13fe3494e16a8b519e573f14d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import batch_iter\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    e = y - tx @ w\n",
    "    return - 1/len(e) * tx.T @ e\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        total_batches = len(y) // batch_size\n",
    "        avg_loss = 0\n",
    "        for (batch_y, batch_tx) in batch_iter(y, tx, batch_size=batch_size, num_batches=total_batches):\n",
    "            grad = compute_gradient(batch_y, batch_tx, w)\n",
    "            avg_loss += compute_loss(batch_y, batch_tx, w)\n",
    "            w = w - gamma * grad\n",
    "        avg_loss /= total_batches\n",
    "        losses.append(avg_loss)\n",
    "        ws.append(w)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=avg_loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=18.647730025747677, w0=75.29561736161634, w1=14.860441684443261\n",
      "SGD iter. 1/49: loss=16.999274376344207, w0=73.42789217139433, w1=14.378866490653683\n",
      "SGD iter. 2/49: loss=17.05027494337455, w0=76.70600113071669, w1=13.298845313048936\n",
      "SGD iter. 3/49: loss=16.93290425609236, w0=71.41428417919289, w1=13.804937159330382\n",
      "SGD iter. 4/49: loss=17.011293510221996, w0=73.26506105540919, w1=12.472771194043814\n",
      "SGD iter. 5/49: loss=16.970833299202834, w0=73.16578022810862, w1=11.83440656680517\n",
      "SGD iter. 6/49: loss=17.015588273216217, w0=74.21730433532116, w1=15.428234404498626\n",
      "SGD iter. 7/49: loss=17.03287685917865, w0=71.88114722111875, w1=14.382385994859861\n",
      "SGD iter. 8/49: loss=16.95517132354711, w0=73.90616492709225, w1=14.078184869304883\n",
      "SGD iter. 9/49: loss=17.07463122901692, w0=72.55827930161843, w1=13.243124730475701\n",
      "SGD iter. 10/49: loss=16.951935204790598, w0=73.5669575393563, w1=11.56736889543364\n",
      "SGD iter. 11/49: loss=16.9876988067353, w0=75.90751936513537, w1=13.89945167291015\n",
      "SGD iter. 12/49: loss=17.07145253360796, w0=71.3114223403775, w1=10.096981625757198\n",
      "SGD iter. 13/49: loss=16.929528911637565, w0=74.72715110796916, w1=14.116638835285045\n",
      "SGD iter. 14/49: loss=16.859452707342523, w0=72.96689532243944, w1=12.7646628903185\n",
      "SGD iter. 15/49: loss=16.994560101371977, w0=72.614358222877, w1=11.996361409898768\n",
      "SGD iter. 16/49: loss=16.972750508075855, w0=73.73364746781019, w1=13.745178315933597\n",
      "SGD iter. 17/49: loss=17.054275817821697, w0=71.8367672702279, w1=13.097641956415845\n",
      "SGD iter. 18/49: loss=16.901979954489153, w0=73.12037791561134, w1=12.41063472068982\n",
      "SGD iter. 19/49: loss=16.92031245678931, w0=72.6034061484767, w1=10.493119699347949\n",
      "SGD iter. 20/49: loss=16.95808770952308, w0=70.56351356443935, w1=11.061793326287873\n",
      "SGD iter. 21/49: loss=16.930501632494412, w0=72.88703031352358, w1=11.576595933606097\n",
      "SGD iter. 22/49: loss=17.030994570099626, w0=75.83756737419539, w1=14.436947711386676\n",
      "SGD iter. 23/49: loss=17.03642717504896, w0=72.98438579154231, w1=15.408734282116347\n",
      "SGD iter. 24/49: loss=17.008959929328917, w0=74.9824628441181, w1=12.908280716285022\n",
      "SGD iter. 25/49: loss=16.890616082378703, w0=73.43118310526737, w1=11.966168135546914\n",
      "SGD iter. 26/49: loss=16.985951149810354, w0=73.31622745412785, w1=14.40442967884759\n",
      "SGD iter. 27/49: loss=16.92745322905613, w0=72.67995738318942, w1=14.455793767711317\n",
      "SGD iter. 28/49: loss=16.968122696415655, w0=72.35361550990355, w1=13.59570406900765\n",
      "SGD iter. 29/49: loss=17.07594197537514, w0=74.67537267691907, w1=12.460735965172814\n",
      "SGD iter. 30/49: loss=17.01993009691281, w0=72.76066455709693, w1=12.988597199718203\n",
      "SGD iter. 31/49: loss=16.92873109247427, w0=73.67855180168203, w1=12.442984284235175\n",
      "SGD iter. 32/49: loss=17.019698139129076, w0=71.8263569522502, w1=13.933086329277621\n",
      "SGD iter. 33/49: loss=17.034628732608528, w0=72.47298686731598, w1=15.442463092323926\n",
      "SGD iter. 34/49: loss=16.97076096123558, w0=74.11653519522703, w1=14.432995767658463\n",
      "SGD iter. 35/49: loss=16.964981606127186, w0=71.42252716400984, w1=12.510494841034072\n",
      "SGD iter. 36/49: loss=17.05470158757865, w0=73.0446271809425, w1=14.541876992622887\n",
      "SGD iter. 37/49: loss=17.041824017349224, w0=73.95055433639345, w1=14.382649085495363\n",
      "SGD iter. 38/49: loss=17.071153495739786, w0=71.98368130724371, w1=12.173202169613226\n",
      "SGD iter. 39/49: loss=17.024112739813464, w0=74.99296382416784, w1=13.60663615012412\n",
      "SGD iter. 40/49: loss=17.006770437862183, w0=73.32909517613122, w1=13.751116785932231\n",
      "SGD iter. 41/49: loss=17.023078367916465, w0=72.71804157655038, w1=14.08714091757412\n",
      "SGD iter. 42/49: loss=16.95014662441156, w0=75.11427686647001, w1=13.146770364205913\n",
      "SGD iter. 43/49: loss=17.048650178873526, w0=72.21882752571389, w1=13.439138102494045\n",
      "SGD iter. 44/49: loss=17.04314210400334, w0=73.82074137501645, w1=13.548432826925266\n",
      "SGD iter. 45/49: loss=16.956051022828518, w0=72.60105356241209, w1=12.596665637867092\n",
      "SGD iter. 46/49: loss=16.9436573945215, w0=73.31835076697864, w1=13.75976901889358\n",
      "SGD iter. 47/49: loss=16.95847114936321, w0=73.20275157678083, w1=15.594125289256842\n",
      "SGD iter. 48/49: loss=16.98359949450917, w0=71.53482560579288, w1=11.922048822032838\n",
      "SGD iter. 49/49: loss=17.100675140061423, w0=71.0814204034036, w1=13.322466622978052\n",
      "SGD: execution time=6.773 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e426ae0db04a4d8fed7ae66e3d1c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358524, w0=51.847464098448434, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=318.2821247015961, w0=67.40170332798299, w1=10.041754328050118\n",
      "GD iter. 2/49: loss=88.6423556165127, w0=72.06797509684336, w1=10.736952704607411\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574596\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631796\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248088, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249234, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038407\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140231, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670435\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.0348943381935\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650423\n",
      "GD iter. 15/49: loss=65.93073010260393, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927509, w1=11.034894851738622\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.03489486560434\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260338, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.03489486598882\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989015\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.034894865989099\n",
      "GD iter. 30/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD: execution time=0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma) \n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6100d54bc68a41f3b1b6305687eba69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    return - 1/N * np.sign(y - tx @ w) @ tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costs import mae\n",
    "\n",
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        \n",
    "        loss = compute_loss(y, tx, w, loss=mae)\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        w = w - gamma * subgrad\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=37.03390292746319, w0=0.7000000000000004, w1=7.338997388192976e-16\n",
      "SubGD iter. 1/499: loss=36.68390292746319, w0=1.4000000000000008, w1=1.4677994776385952e-15\n",
      "SubGD iter. 2/499: loss=36.333902927463186, w0=2.1000000000000014, w1=2.2016992164578927e-15\n",
      "SubGD iter. 3/499: loss=35.983902927463184, w0=2.8000000000000016, w1=2.9355989552771903e-15\n",
      "SubGD iter. 4/499: loss=35.63390292746319, w0=3.5000000000000018, w1=3.669498694096488e-15\n",
      "SubGD iter. 5/499: loss=35.283902927463195, w0=4.200000000000002, w1=4.403398432915785e-15\n",
      "SubGD iter. 6/499: loss=34.93390292746319, w0=4.900000000000002, w1=5.137298171735083e-15\n",
      "SubGD iter. 7/499: loss=34.583902927463186, w0=5.600000000000002, w1=5.87119791055438e-15\n",
      "SubGD iter. 8/499: loss=34.233902927463184, w0=6.3000000000000025, w1=6.605097649373677e-15\n",
      "SubGD iter. 9/499: loss=33.88390292746319, w0=7.000000000000003, w1=7.338997388192974e-15\n",
      "SubGD iter. 10/499: loss=33.53390292746319, w0=7.700000000000003, w1=8.072897127012273e-15\n",
      "SubGD iter. 11/499: loss=33.18390292746319, w0=8.400000000000004, w1=8.80679686583157e-15\n",
      "SubGD iter. 12/499: loss=32.83390292746319, w0=9.100000000000005, w1=9.540696604650869e-15\n",
      "SubGD iter. 13/499: loss=32.483902927463184, w0=9.800000000000006, w1=1.0274596343470167e-14\n",
      "SubGD iter. 14/499: loss=32.13390292746319, w0=10.500000000000007, w1=1.1008496082289465e-14\n",
      "SubGD iter. 15/499: loss=31.783902927463185, w0=11.200000000000008, w1=1.1742395821108763e-14\n",
      "SubGD iter. 16/499: loss=31.433902927463187, w0=11.90000000000001, w1=1.2476295559928061e-14\n",
      "SubGD iter. 17/499: loss=31.083902927463186, w0=12.60000000000001, w1=1.3210195298747359e-14\n",
      "SubGD iter. 18/499: loss=30.73390292746318, w0=13.300000000000011, w1=1.3944095037566657e-14\n",
      "SubGD iter. 19/499: loss=30.383902927463186, w0=14.000000000000012, w1=1.4677994776385955e-14\n",
      "SubGD iter. 20/499: loss=30.033902927463185, w0=14.700000000000014, w1=1.5411894515205253e-14\n",
      "SubGD iter. 21/499: loss=29.683902927463183, w0=15.400000000000015, w1=1.614579425402455e-14\n",
      "SubGD iter. 22/499: loss=29.333902927463182, w0=16.100000000000016, w1=1.687969399284385e-14\n",
      "SubGD iter. 23/499: loss=28.98390292746318, w0=16.800000000000015, w1=1.7613593731663148e-14\n",
      "SubGD iter. 24/499: loss=28.633902927463183, w0=17.500000000000014, w1=1.8347493470482446e-14\n",
      "SubGD iter. 25/499: loss=28.283902927463185, w0=18.200000000000014, w1=1.9081393209301744e-14\n",
      "SubGD iter. 26/499: loss=27.933902927463183, w0=18.900000000000013, w1=1.9815292948121042e-14\n",
      "SubGD iter. 27/499: loss=27.583902927463186, w0=19.600000000000012, w1=2.054919268694034e-14\n",
      "SubGD iter. 28/499: loss=27.23390292746318, w0=20.30000000000001, w1=2.1283092425759638e-14\n",
      "SubGD iter. 29/499: loss=26.883902927463183, w0=21.00000000000001, w1=2.2016992164578936e-14\n",
      "SubGD iter. 30/499: loss=26.533902927463185, w0=21.70000000000001, w1=2.2750891903398234e-14\n",
      "SubGD iter. 31/499: loss=26.183902927463183, w0=22.40000000000001, w1=2.3484791642217532e-14\n",
      "SubGD iter. 32/499: loss=25.833902927463186, w0=23.10000000000001, w1=2.421869138103683e-14\n",
      "SubGD iter. 33/499: loss=25.48390292746318, w0=23.800000000000008, w1=2.4952591119856128e-14\n",
      "SubGD iter. 34/499: loss=25.133902927463186, w0=24.500000000000007, w1=2.5686490858675426e-14\n",
      "SubGD iter. 35/499: loss=24.78390292746319, w0=25.200000000000006, w1=2.6420390597494725e-14\n",
      "SubGD iter. 36/499: loss=24.433902927463187, w0=25.900000000000006, w1=2.7154290336314023e-14\n",
      "SubGD iter. 37/499: loss=24.083902927463186, w0=26.600000000000005, w1=2.788819007513332e-14\n",
      "SubGD iter. 38/499: loss=23.733902927463184, w0=27.300000000000004, w1=2.862208981395262e-14\n",
      "SubGD iter. 39/499: loss=23.383902927463186, w0=28.000000000000004, w1=2.935598955277192e-14\n",
      "SubGD iter. 40/499: loss=23.03390292746319, w0=28.700000000000003, w1=3.0089889291591215e-14\n",
      "SubGD iter. 41/499: loss=22.683902927463187, w0=29.400000000000002, w1=3.082378903041051e-14\n",
      "SubGD iter. 42/499: loss=22.33390292746319, w0=30.1, w1=3.155768876922981e-14\n",
      "SubGD iter. 43/499: loss=21.98390292746319, w0=30.8, w1=3.229158850804911e-14\n",
      "SubGD iter. 44/499: loss=21.63390292746319, w0=31.5, w1=3.302548824686841e-14\n",
      "SubGD iter. 45/499: loss=21.283902927463192, w0=32.2, w1=3.3759387985687705e-14\n",
      "SubGD iter. 46/499: loss=20.933902927463187, w0=32.900000000000006, w1=3.4493287724507003e-14\n",
      "SubGD iter. 47/499: loss=20.58390292746319, w0=33.60000000000001, w1=3.52271874633263e-14\n",
      "SubGD iter. 48/499: loss=20.233902927463184, w0=34.30000000000001, w1=3.59610872021456e-14\n",
      "SubGD iter. 49/499: loss=19.883902927463183, w0=35.000000000000014, w1=3.66949869409649e-14\n",
      "SubGD iter. 50/499: loss=19.533902927463185, w0=35.70000000000002, w1=3.7428886679784196e-14\n",
      "SubGD iter. 51/499: loss=19.183902927463183, w0=36.40000000000002, w1=3.8162786418603494e-14\n",
      "SubGD iter. 52/499: loss=18.833902927463182, w0=37.10000000000002, w1=3.889668615742279e-14\n",
      "SubGD iter. 53/499: loss=18.483902927463177, w0=37.800000000000026, w1=3.963058589624209e-14\n",
      "SubGD iter. 54/499: loss=18.13390292746318, w0=38.50000000000003, w1=4.036448563506139e-14\n",
      "SubGD iter. 55/499: loss=17.783902927463174, w0=39.20000000000003, w1=4.1098385373880686e-14\n",
      "SubGD iter. 56/499: loss=17.433902927463176, w0=39.900000000000034, w1=4.1832285112699984e-14\n",
      "SubGD iter. 57/499: loss=17.08390292746317, w0=40.60000000000004, w1=4.256618485151928e-14\n",
      "SubGD iter. 58/499: loss=16.733902927463173, w0=41.30000000000004, w1=4.330008459033858e-14\n",
      "SubGD iter. 59/499: loss=16.38390292746317, w0=42.00000000000004, w1=4.403398432915788e-14\n",
      "SubGD iter. 60/499: loss=16.033902927463167, w0=42.700000000000045, w1=4.4767884067977177e-14\n",
      "SubGD iter. 61/499: loss=15.683902927463166, w0=43.40000000000005, w1=4.5501783806796475e-14\n",
      "SubGD iter. 62/499: loss=15.333902927463166, w0=44.10000000000005, w1=4.623568354561577e-14\n",
      "SubGD iter. 63/499: loss=14.983902927463163, w0=44.800000000000054, w1=4.696958328443507e-14\n",
      "SubGD iter. 64/499: loss=14.633902927463161, w0=45.50000000000006, w1=4.770348302325437e-14\n",
      "SubGD iter. 65/499: loss=14.28390292746316, w0=46.20000000000006, w1=4.843738276207367e-14\n",
      "SubGD iter. 66/499: loss=13.933902927463159, w0=46.90000000000006, w1=4.9171282500892965e-14\n",
      "SubGD iter. 67/499: loss=13.586635104834446, w0=47.59306930693076, w1=0.011147845678279311\n",
      "SubGD iter. 68/499: loss=13.245225781875591, w0=48.279207920792146, w1=0.03308574108990771\n",
      "SubGD iter. 69/499: loss=12.908606161385078, w0=48.965346534653534, w1=0.055023636501536105\n",
      "SubGD iter. 70/499: loss=12.577519717328217, w0=49.630693069307, w1=0.10538326388308662\n",
      "SubGD iter. 71/499: loss=12.26205170694738, w0=50.28910891089116, w1=0.16746568532794298\n",
      "SubGD iter. 72/499: loss=11.949647673017784, w0=50.94752475247532, w1=0.22954810677279933\n",
      "SubGD iter. 73/499: loss=11.642196462828561, w0=51.59207920792086, w1=0.3124251293274841\n",
      "SubGD iter. 74/499: loss=11.343438222090912, w0=52.22277227722779, w1=0.41195013288400817\n",
      "SubGD iter. 75/499: loss=11.053133784820265, w0=52.84653465346541, w1=0.5208167847923848\n",
      "SubGD iter. 76/499: loss=10.768909414004206, w0=53.45643564356442, w1=0.6457900912636085\n",
      "SubGD iter. 77/499: loss=10.493169937314223, w0=54.059405940594125, w1=0.7796904498577307\n",
      "SubGD iter. 78/499: loss=10.22278046831021, w0=54.655445544554524, w1=0.9197570104995785\n",
      "SubGD iter. 79/499: loss=9.95595507947891, w0=55.244554455445616, w1=1.0670920297850004\n",
      "SubGD iter. 80/499: loss=9.694822045281603, w0=55.81980198019809, w1=1.2261255948210856\n",
      "SubGD iter. 81/499: loss=9.44399453219793, w0=56.36732673267334, w1=1.410709342622222\n",
      "SubGD iter. 82/499: loss=9.207980250927106, w0=56.900990099009974, w1=1.6058537322202775\n",
      "SubGD iter. 83/499: loss=8.977449271520182, w0=57.4277227722773, w1=1.8087628022939701\n",
      "SubGD iter. 84/499: loss=8.752878828289901, w0=57.9336633663367, w1=2.0285064197514777\n",
      "SubGD iter. 85/499: loss=8.537478713465797, w0=58.4326732673268, w1=2.2494370848672856\n",
      "SubGD iter. 86/499: loss=8.32648364875494, w0=58.91089108910898, w1=2.4837982986028417\n",
      "SubGD iter. 87/499: loss=8.124270365748352, w0=59.38217821782185, w1=2.726024555353158\n",
      "SubGD iter. 88/499: loss=7.924552606327069, w0=59.83960396039611, w1=2.9787423334691434\n",
      "SubGD iter. 89/499: loss=7.7334598956156535, w0=60.26237623762383, w1=3.2515286693554453\n",
      "SubGD iter. 90/499: loss=7.554147310756099, w0=60.67821782178225, w1=3.5270865794242865\n",
      "SubGD iter. 91/499: loss=7.377448172961407, w0=61.087128712871355, w1=3.806459183951822\n",
      "SubGD iter. 92/499: loss=7.202264480810132, w0=61.49603960396046, w1=4.085831788479357\n",
      "SubGD iter. 93/499: loss=7.0278935140636305, w0=61.891089108910954, w1=4.373839384328614\n",
      "SubGD iter. 94/499: loss=6.857310455802809, w0=62.27920792079214, w1=4.6660374695320534\n",
      "SubGD iter. 95/499: loss=6.690618153642069, w0=62.653465346534716, w1=4.959829093241775\n",
      "SubGD iter. 96/499: loss=6.529410807583109, w0=63.020792079207986, w1=5.257057192056645\n",
      "SubGD iter. 97/499: loss=6.370125862169612, w0=63.38118811881195, w1=5.560434316352412\n",
      "SubGD iter. 98/499: loss=6.2116094443780465, w0=63.74158415841591, w1=5.8638114406481785\n",
      "SubGD iter. 99/499: loss=6.053780865950578, w0=64.08811881188126, w1=6.172402175278553\n",
      "SubGD iter. 100/499: loss=5.900311048699061, w0=64.42772277227729, w1=6.486369310516503\n",
      "SubGD iter. 101/499: loss=5.747520897323205, w0=64.76732673267333, w1=6.800336445754453\n",
      "SubGD iter. 102/499: loss=5.594730745947349, w0=65.10693069306936, w1=7.114303580992402\n",
      "SubGD iter. 103/499: loss=5.441940594571494, w0=65.44653465346539, w1=7.428270716230352\n",
      "SubGD iter. 104/499: loss=5.292296704156595, w0=65.76534653465352, w1=7.747893210218629\n",
      "SubGD iter. 105/499: loss=5.147908267159464, w0=66.07029702970303, w1=8.073669686866909\n",
      "SubGD iter. 106/499: loss=5.005676040610674, w0=66.37524752475254, w1=8.399446163515188\n",
      "SubGD iter. 107/499: loss=4.864042163334059, w0=66.66633663366343, w1=8.732970280417394\n",
      "SubGD iter. 108/499: loss=4.724062730561248, w0=66.95742574257433, w1=9.0664943973196\n",
      "SubGD iter. 109/499: loss=4.5855205520483295, w0=67.23465346534661, w1=9.398630319470293\n",
      "SubGD iter. 110/499: loss=4.451828065579475, w0=67.51188118811889, w1=9.730766241620985\n",
      "SubGD iter. 111/499: loss=4.3181355791106215, w0=67.78910891089117, w1=10.062902163771678\n",
      "SubGD iter. 112/499: loss=4.188075960151181, w0=68.06633663366345, w1=10.363999289979425\n",
      "SubGD iter. 113/499: loss=4.070270419375742, w0=68.32970297029712, w1=10.660466909273616\n",
      "SubGD iter. 114/499: loss=3.95927225079863, w0=68.59306930693079, w1=10.943174379960817\n",
      "SubGD iter. 115/499: loss=3.8526398641884945, w0=68.85643564356445, w1=11.225881850648019\n",
      "SubGD iter. 116/499: loss=3.746847915589315, w0=69.11287128712881, w1=11.50439584358221\n",
      "SubGD iter. 117/499: loss=3.6449962028717025, w0=69.35544554455456, w1=11.788201893067754\n",
      "SubGD iter. 118/499: loss=3.548617017890767, w0=69.58415841584169, w1=12.060911465190975\n",
      "SubGD iter. 119/499: loss=3.4599526473344557, w0=69.8059405940595, w1=12.324245668386052\n",
      "SubGD iter. 120/499: loss=3.3752867636577224, w0=70.02772277227733, w1=12.587579871581129\n",
      "SubGD iter. 121/499: loss=3.292372405402827, w0=70.25643564356446, w1=12.824765405096487\n",
      "SubGD iter. 122/499: loss=3.2151716381738975, w0=70.47821782178228, w1=13.065616959310152\n",
      "SubGD iter. 123/499: loss=3.139035740945171, w0=70.6930693069308, w1=13.302953389983916\n",
      "SubGD iter. 124/499: loss=3.0668316646316565, w0=70.8940594059407, w1=13.525403099312921\n",
      "SubGD iter. 125/499: loss=3.0029203991715105, w0=71.08811881188129, w1=13.742945617944216\n",
      "SubGD iter. 126/499: loss=2.942510912611605, w0=71.27524752475257, w1=13.953548196006848\n",
      "SubGD iter. 127/499: loss=2.885817626134825, w0=71.46237623762386, w1=14.16415077406948\n",
      "SubGD iter. 128/499: loss=2.833581030895125, w0=71.62178217821791, w1=14.349779559473179\n",
      "SubGD iter. 129/499: loss=2.7933633829965694, w0=71.75346534653474, w1=14.516890107612316\n",
      "SubGD iter. 130/499: loss=2.7619239060801903, w0=71.87128712871295, w1=14.670791185324191\n",
      "SubGD iter. 131/499: loss=2.740046854295934, w0=71.95445544554464, w1=14.780276456654526\n",
      "SubGD iter. 132/499: loss=2.7265440017510105, w0=72.03762376237633, w1=14.889761727984862\n",
      "SubGD iter. 133/499: loss=2.7136963154314513, w0=72.1069306930694, w1=14.985916181776732\n",
      "SubGD iter. 134/499: loss=2.7036612228413746, w0=72.17623762376247, w1=15.082070635568602\n",
      "SubGD iter. 135/499: loss=2.693626130251298, w0=72.24554455445555, w1=15.178225089360472\n",
      "SubGD iter. 136/499: loss=2.685230390169347, w0=72.30099009901001, w1=15.259723489715915\n",
      "SubGD iter. 137/499: loss=2.6787032616673696, w0=72.34950495049516, w1=15.335091856448143\n",
      "SubGD iter. 138/499: loss=2.6729646320112908, w0=72.39801980198031, w1=15.41046022318037\n",
      "SubGD iter. 139/499: loss=2.6678573297587365, w0=72.43267326732685, w1=15.46996178675573\n",
      "SubGD iter. 140/499: loss=2.66502195523268, w0=72.46039603960408, w1=15.518645285832815\n",
      "SubGD iter. 141/499: loss=2.6628382141366123, w0=72.48811881188131, w1=15.561592159086493\n",
      "SubGD iter. 142/499: loss=2.6610883632632953, w0=72.50198019801992, w1=15.597828332032531\n",
      "SubGD iter. 143/499: loss=2.660055654821556, w0=72.52277227722784, w1=15.624722856626718\n",
      "SubGD iter. 144/499: loss=2.6592391424492186, w0=72.55049504950507, w1=15.642690329098006\n",
      "SubGD iter. 145/499: loss=2.6586200242825733, w0=72.56435643564369, w1=15.664356578291097\n",
      "SubGD iter. 146/499: loss=2.6582032739757717, w0=72.58514851485161, w1=15.67709577536129\n",
      "SubGD iter. 147/499: loss=2.6577785613330716, w0=72.60594059405953, w1=15.689834972431482\n",
      "SubGD iter. 148/499: loss=2.657353848690369, w0=72.62673267326745, w1=15.702574169501675\n",
      "SubGD iter. 149/499: loss=2.6569384404610834, w0=72.64059405940607, w1=15.724240418694766\n",
      "SubGD iter. 150/499: loss=2.656526123435691, w0=72.66138613861399, w1=15.736979615764959\n",
      "SubGD iter. 151/499: loss=2.656188919512194, w0=72.6683168316833, w1=15.748110294231285\n",
      "SubGD iter. 152/499: loss=2.656066114862521, w0=72.6752475247526, w1=15.759240972697611\n",
      "SubGD iter. 153/499: loss=2.6559433102128485, w0=72.68217821782191, w1=15.770371651163938\n",
      "SubGD iter. 154/499: loss=2.655841783049217, w0=72.68217821782191, w1=15.774323911906691\n",
      "SubGD iter. 155/499: loss=2.65583062564566, w0=72.68217821782191, w1=15.778276172649445\n",
      "SubGD iter. 156/499: loss=2.6558194682421044, w0=72.68217821782191, w1=15.782228433392198\n",
      "SubGD iter. 157/499: loss=2.655808310838548, w0=72.68217821782191, w1=15.786180694134952\n",
      "SubGD iter. 158/499: loss=2.6557971534349925, w0=72.68217821782191, w1=15.790132954877706\n",
      "SubGD iter. 159/499: loss=2.6557859960314367, w0=72.68217821782191, w1=15.79408521562046\n",
      "SubGD iter. 160/499: loss=2.6557748386278797, w0=72.68217821782191, w1=15.798037476363213\n",
      "SubGD iter. 161/499: loss=2.6557636812243235, w0=72.68217821782191, w1=15.801989737105966\n",
      "SubGD iter. 162/499: loss=2.6557525238207678, w0=72.68217821782191, w1=15.80594199784872\n",
      "SubGD iter. 163/499: loss=2.6557413664172107, w0=72.68217821782191, w1=15.809894258591473\n",
      "SubGD iter. 164/499: loss=2.6557302090136545, w0=72.68217821782191, w1=15.813846519334227\n",
      "SubGD iter. 165/499: loss=2.655719051610099, w0=72.68217821782191, w1=15.81779878007698\n",
      "SubGD iter. 166/499: loss=2.6557078942065426, w0=72.68217821782191, w1=15.821751040819734\n",
      "SubGD iter. 167/499: loss=2.655696736802987, w0=72.68217821782191, w1=15.825703301562488\n",
      "SubGD iter. 168/499: loss=2.65568557939943, w0=72.68217821782191, w1=15.829655562305241\n",
      "SubGD iter. 169/499: loss=2.6556744219958737, w0=72.68217821782191, w1=15.833607823047995\n",
      "SubGD iter. 170/499: loss=2.655663264592317, w0=72.68217821782191, w1=15.837560083790748\n",
      "SubGD iter. 171/499: loss=2.6556521071887613, w0=72.68217821782191, w1=15.841512344533502\n",
      "SubGD iter. 172/499: loss=2.6556409497852047, w0=72.68217821782191, w1=15.845464605276256\n",
      "SubGD iter. 173/499: loss=2.655629792381649, w0=72.68217821782191, w1=15.84941686601901\n",
      "SubGD iter. 174/499: loss=2.655618634978093, w0=72.68217821782191, w1=15.853369126761763\n",
      "SubGD iter. 175/499: loss=2.6556074775745366, w0=72.68217821782191, w1=15.857321387504516\n",
      "SubGD iter. 176/499: loss=2.65559632017098, w0=72.68217821782191, w1=15.86127364824727\n",
      "SubGD iter. 177/499: loss=2.655585162767424, w0=72.68217821782191, w1=15.865225908990023\n",
      "SubGD iter. 178/499: loss=2.655574005363868, w0=72.68217821782191, w1=15.869178169732777\n",
      "SubGD iter. 179/499: loss=2.6555628479603115, w0=72.68217821782191, w1=15.87313043047553\n",
      "SubGD iter. 180/499: loss=2.655551690556755, w0=72.68217821782191, w1=15.877082691218284\n",
      "SubGD iter. 181/499: loss=2.655540533153199, w0=72.68217821782191, w1=15.881034951961038\n",
      "SubGD iter. 182/499: loss=2.6555293757496425, w0=72.68217821782191, w1=15.884987212703791\n",
      "SubGD iter. 183/499: loss=2.655518218346087, w0=72.68217821782191, w1=15.888939473446545\n",
      "SubGD iter. 184/499: loss=2.65550706094253, w0=72.68217821782191, w1=15.892891734189298\n",
      "SubGD iter. 185/499: loss=2.655495903538974, w0=72.68217821782191, w1=15.896843994932052\n",
      "SubGD iter. 186/499: loss=2.6554847461354183, w0=72.68217821782191, w1=15.900796255674805\n",
      "SubGD iter. 187/499: loss=2.6554735887318617, w0=72.68217821782191, w1=15.904748516417559\n",
      "SubGD iter. 188/499: loss=2.655462431328305, w0=72.68217821782191, w1=15.908700777160313\n",
      "SubGD iter. 189/499: loss=2.6554512739247493, w0=72.68217821782191, w1=15.912653037903066\n",
      "SubGD iter. 190/499: loss=2.6554568530306906, w0=72.6752475247526, w1=15.910526938117329\n",
      "SubGD iter. 191/499: loss=2.655446118593135, w0=72.6752475247526, w1=15.914479198860082\n",
      "SubGD iter. 192/499: loss=2.6554349611895782, w0=72.6752475247526, w1=15.918431459602836\n",
      "SubGD iter. 193/499: loss=2.6554313180269173, w0=72.6683168316833, w1=15.916305359817098\n",
      "SubGD iter. 194/499: loss=2.655429805857964, w0=72.6683168316833, w1=15.920257620559852\n",
      "SubGD iter. 195/499: loss=2.6554186484544076, w0=72.6683168316833, w1=15.924209881302605\n",
      "SubGD iter. 196/499: loss=2.6554074910508514, w0=72.6683168316833, w1=15.928162142045359\n",
      "SubGD iter. 197/499: loss=2.6554117850950854, w0=72.66138613861399, w1=15.926036042259621\n",
      "SubGD iter. 198/499: loss=2.6554023357192373, w0=72.66138613861399, w1=15.929988303002375\n",
      "SubGD iter. 199/499: loss=2.6553911783156807, w0=72.66138613861399, w1=15.933940563745129\n",
      "SubGD iter. 200/499: loss=2.6553862500913117, w0=72.65445544554468, w1=15.931814463959391\n",
      "SubGD iter. 201/499: loss=2.6553860229840662, w0=72.65445544554468, w1=15.935766724702145\n",
      "SubGD iter. 202/499: loss=2.6553748655805105, w0=72.65445544554468, w1=15.939718985444898\n",
      "SubGD iter. 203/499: loss=2.655363708176954, w0=72.65445544554468, w1=15.943671246187652\n",
      "SubGD iter. 204/499: loss=2.6553667171594797, w0=72.64752475247538, w1=15.941545146401914\n",
      "SubGD iter. 205/499: loss=2.6553585528453394, w0=72.64752475247538, w1=15.945497407144668\n",
      "SubGD iter. 206/499: loss=2.6553473954417828, w0=72.64752475247538, w1=15.949449667887421\n",
      "SubGD iter. 207/499: loss=2.655341182155706, w0=72.64059405940607, w1=15.947323568101684\n",
      "SubGD iter. 208/499: loss=2.6553422401101687, w0=72.64059405940607, w1=15.951275828844437\n",
      "SubGD iter. 209/499: loss=2.655331082706612, w0=72.64059405940607, w1=15.955228089587191\n",
      "SubGD iter. 210/499: loss=2.655319925303056, w0=72.64059405940607, w1=15.959180350329945\n",
      "SubGD iter. 211/499: loss=2.655321649223874, w0=72.63366336633676, w1=15.957054250544207\n",
      "SubGD iter. 212/499: loss=2.655314769971442, w0=72.63366336633676, w1=15.96100651128696\n",
      "SubGD iter. 213/499: loss=2.6553036125678853, w0=72.63366336633676, w1=15.964958772029714\n",
      "SubGD iter. 214/499: loss=2.6552961142201, w0=72.62673267326745, w1=15.962832672243977\n",
      "SubGD iter. 215/499: loss=2.655316591549513, w0=72.63366336633676, w1=15.96730137205138\n",
      "SubGD iter. 216/499: loss=2.655299671792532, w0=72.62673267326745, w1=15.965175272265643\n",
      "SubGD iter. 217/499: loss=2.655309114137895, w0=72.63366336633676, w1=15.969643972073047\n",
      "SubGD iter. 218/499: loss=2.655303229364963, w0=72.62673267326745, w1=15.96751787228731\n",
      "SubGD iter. 219/499: loss=2.6553016367262767, w0=72.63366336633676, w1=15.971986572094714\n",
      "SubGD iter. 220/499: loss=2.6553067869373943, w0=72.62673267326745, w1=15.969860472308977\n",
      "SubGD iter. 221/499: loss=2.655294159314658, w0=72.63366336633676, w1=15.97432917211638\n",
      "SubGD iter. 222/499: loss=2.6553103445098265, w0=72.62673267326745, w1=15.972203072330643\n",
      "SubGD iter. 223/499: loss=2.6552874830749427, w0=72.62673267326745, w1=15.970593411609556\n",
      "SubGD iter. 224/499: loss=2.655291819824865, w0=72.63366336633676, w1=15.97506211141696\n",
      "SubGD iter. 225/499: loss=2.6553114575827474, w0=72.62673267326745, w1=15.972936011631223\n",
      "SubGD iter. 226/499: loss=2.6552883257775157, w0=72.62673267326745, w1=15.971326350910136\n",
      "SubGD iter. 227/499: loss=2.65528948033507, w0=72.63366336633676, w1=15.97579505071754\n",
      "SubGD iter. 228/499: loss=2.655312570655669, w0=72.62673267326745, w1=15.973668950931803\n",
      "SubGD iter. 229/499: loss=2.6552891684800906, w0=72.62673267326745, w1=15.972059290210716\n",
      "SubGD iter. 230/499: loss=2.655287317760349, w0=72.62673267326745, w1=15.970449629489629\n",
      "SubGD iter. 231/499: loss=2.655292278767101, w0=72.63366336633676, w1=15.974918329297033\n",
      "SubGD iter. 232/499: loss=2.65531123922908, w0=72.62673267326745, w1=15.972792229511295\n",
      "SubGD iter. 233/499: loss=2.6552881604629235, w0=72.62673267326745, w1=15.971182568790208\n",
      "SubGD iter. 234/499: loss=2.6552899392773073, w0=72.63366336633676, w1=15.975651268597613\n",
      "SubGD iter. 235/499: loss=2.6553123523020017, w0=72.62673267326745, w1=15.973525168811875\n",
      "SubGD iter. 236/499: loss=2.655289003165497, w0=72.62673267326745, w1=15.971915508090788\n",
      "SubGD iter. 237/499: loss=2.6552875997875134, w0=72.63366336633676, w1=15.976384207898192\n",
      "SubGD iter. 238/499: loss=2.6553134653749235, w0=72.62673267326745, w1=15.974258108112455\n",
      "SubGD iter. 239/499: loss=2.65528984586807, w0=72.62673267326745, w1=15.972648447391368\n",
      "SubGD iter. 240/499: loss=2.6552879951483295, w0=72.62673267326745, w1=15.971038786670281\n",
      "SubGD iter. 241/499: loss=2.655290398219544, w0=72.63366336633676, w1=15.975507486477685\n",
      "SubGD iter. 242/499: loss=2.6553121339483345, w0=72.62673267326745, w1=15.973381386691948\n",
      "SubGD iter. 243/499: loss=2.655288837850903, w0=72.62673267326745, w1=15.97177172597086\n",
      "SubGD iter. 244/499: loss=2.65528805872975, w0=72.63366336633676, w1=15.976240425778265\n",
      "SubGD iter. 245/499: loss=2.6553132470212555, w0=72.62673267326745, w1=15.974114325992527\n",
      "SubGD iter. 246/499: loss=2.655289680553477, w0=72.62673267326745, w1=15.97250466527144\n",
      "SubGD iter. 247/499: loss=2.655287829833736, w0=72.62673267326745, w1=15.970895004550353\n",
      "SubGD iter. 248/499: loss=2.655290857161781, w0=72.63366336633676, w1=15.975363704357758\n",
      "SubGD iter. 249/499: loss=2.655311915594666, w0=72.62673267326745, w1=15.97323760457202\n",
      "SubGD iter. 250/499: loss=2.65528867253631, w0=72.62673267326745, w1=15.971627943850933\n",
      "SubGD iter. 251/499: loss=2.6552885176719876, w0=72.63366336633676, w1=15.976096643658337\n",
      "SubGD iter. 252/499: loss=2.655313028667588, w0=72.62673267326745, w1=15.9739705438726\n",
      "SubGD iter. 253/499: loss=2.655289515238883, w0=72.62673267326745, w1=15.972360883151513\n",
      "SubGD iter. 254/499: loss=2.655287664519142, w0=72.62673267326745, w1=15.970751222430426\n",
      "SubGD iter. 255/499: loss=2.655291316104018, w0=72.63366336633676, w1=15.97521992223783\n",
      "SubGD iter. 256/499: loss=2.655311697240999, w0=72.62673267326745, w1=15.973093822452093\n",
      "SubGD iter. 257/499: loss=2.6552885072217163, w0=72.62673267326745, w1=15.971484161731006\n",
      "SubGD iter. 258/499: loss=2.6552889766142243, w0=72.63366336633676, w1=15.97595286153841\n",
      "SubGD iter. 259/499: loss=2.6553128103139207, w0=72.62673267326745, w1=15.973826761752672\n",
      "SubGD iter. 260/499: loss=2.6552893499242898, w0=72.62673267326745, w1=15.972217101031585\n",
      "SubGD iter. 261/499: loss=2.6552874992045497, w0=72.62673267326745, w1=15.970607440310499\n",
      "SubGD iter. 262/499: loss=2.6552917750462544, w0=72.63366336633676, w1=15.975076140117903\n",
      "SubGD iter. 263/499: loss=2.6553114788873318, w0=72.62673267326745, w1=15.972950040332165\n",
      "SubGD iter. 264/499: loss=2.655288341907123, w0=72.62673267326745, w1=15.971340379611078\n",
      "SubGD iter. 265/499: loss=2.6552894355564605, w0=72.63366336633676, w1=15.975809079418482\n",
      "SubGD iter. 266/499: loss=2.6553125919602536, w0=72.62673267326745, w1=15.973682979632745\n",
      "SubGD iter. 267/499: loss=2.655289184609696, w0=72.62673267326745, w1=15.972073318911658\n",
      "SubGD iter. 268/499: loss=2.6552873338899556, w0=72.62673267326745, w1=15.970463658190571\n",
      "SubGD iter. 269/499: loss=2.6552922339884915, w0=72.63366336633676, w1=15.974932357997975\n",
      "SubGD iter. 270/499: loss=2.6553112605336646, w0=72.62673267326745, w1=15.972806258212238\n",
      "SubGD iter. 271/499: loss=2.655288176592529, w0=72.62673267326745, w1=15.97119659749115\n",
      "SubGD iter. 272/499: loss=2.6552898944986985, w0=72.63366336633676, w1=15.975665297298555\n",
      "SubGD iter. 273/499: loss=2.6553123736065856, w0=72.62673267326745, w1=15.973539197512817\n",
      "SubGD iter. 274/499: loss=2.655289019295103, w0=72.62673267326745, w1=15.97192953679173\n",
      "SubGD iter. 275/499: loss=2.6552875550089046, w0=72.63366336633676, w1=15.976398236599135\n",
      "SubGD iter. 276/499: loss=2.655313486679507, w0=72.62673267326745, w1=15.974272136813397\n",
      "SubGD iter. 277/499: loss=2.6552898619976766, w0=72.62673267326745, w1=15.97266247609231\n",
      "SubGD iter. 278/499: loss=2.6552880112779356, w0=72.62673267326745, w1=15.971052815371223\n",
      "SubGD iter. 279/499: loss=2.6552903534409347, w0=72.63366336633676, w1=15.975521515178627\n",
      "SubGD iter. 280/499: loss=2.6553121552529184, w0=72.62673267326745, w1=15.97339541539289\n",
      "SubGD iter. 281/499: loss=2.65528885398051, w0=72.62673267326745, w1=15.971785754671803\n",
      "SubGD iter. 282/499: loss=2.655288013951141, w0=72.63366336633676, w1=15.976254454479207\n",
      "SubGD iter. 283/499: loss=2.65531326832584, w0=72.62673267326745, w1=15.97412835469347\n",
      "SubGD iter. 284/499: loss=2.6552896966830835, w0=72.62673267326745, w1=15.972518693972383\n",
      "SubGD iter. 285/499: loss=2.6552878459633424, w0=72.62673267326745, w1=15.970909033251296\n",
      "SubGD iter. 286/499: loss=2.6552908123831718, w0=72.63366336633676, w1=15.9753777330587\n",
      "SubGD iter. 287/499: loss=2.655311936899251, w0=72.62673267326745, w1=15.973251633272962\n",
      "SubGD iter. 288/499: loss=2.655288688665916, w0=72.62673267326745, w1=15.971641972551875\n",
      "SubGD iter. 289/499: loss=2.655288472893378, w0=72.63366336633676, w1=15.97611067235928\n",
      "SubGD iter. 290/499: loss=2.6553130499721727, w0=72.62673267326745, w1=15.973984572573542\n",
      "SubGD iter. 291/499: loss=2.6552895313684894, w0=72.62673267326745, w1=15.972374911852455\n",
      "SubGD iter. 292/499: loss=2.6552876806487484, w0=72.62673267326745, w1=15.970765251131368\n",
      "SubGD iter. 293/499: loss=2.6552912713254084, w0=72.63366336633676, w1=15.975233950938772\n",
      "SubGD iter. 294/499: loss=2.6553117185455837, w0=72.62673267326745, w1=15.973107851153035\n",
      "SubGD iter. 295/499: loss=2.6552885233513224, w0=72.62673267326745, w1=15.971498190431948\n",
      "SubGD iter. 296/499: loss=2.655288931835615, w0=72.63366336633676, w1=15.975966890239352\n",
      "SubGD iter. 297/499: loss=2.6553128316185046, w0=72.62673267326745, w1=15.973840790453615\n",
      "SubGD iter. 298/499: loss=2.6552893660538963, w0=72.62673267326745, w1=15.972231129732528\n",
      "SubGD iter. 299/499: loss=2.655287515334156, w0=72.62673267326745, w1=15.97062146901144\n",
      "SubGD iter. 300/499: loss=2.655291730267646, w0=72.63366336633676, w1=15.975090168818845\n",
      "SubGD iter. 301/499: loss=2.6553115001919165, w0=72.62673267326745, w1=15.972964069033107\n",
      "SubGD iter. 302/499: loss=2.6552883580367292, w0=72.62673267326745, w1=15.97135440831202\n",
      "SubGD iter. 303/499: loss=2.6552893907778516, w0=72.63366336633676, w1=15.975823108119425\n",
      "SubGD iter. 304/499: loss=2.655312613264837, w0=72.62673267326745, w1=15.973697008333687\n",
      "SubGD iter. 305/499: loss=2.6552892007393027, w0=72.62673267326745, w1=15.9720873476126\n",
      "SubGD iter. 306/499: loss=2.6552873500195617, w0=72.62673267326745, w1=15.970477686891513\n",
      "SubGD iter. 307/499: loss=2.655292189209882, w0=72.63366336633676, w1=15.974946386698917\n",
      "SubGD iter. 308/499: loss=2.6553112818382494, w0=72.62673267326745, w1=15.97282028691318\n",
      "SubGD iter. 309/499: loss=2.6552881927221357, w0=72.62673267326745, w1=15.971210626192093\n",
      "SubGD iter. 310/499: loss=2.655289849720088, w0=72.63366336633676, w1=15.975679325999497\n",
      "SubGD iter. 311/499: loss=2.65531239491117, w0=72.62673267326745, w1=15.97355322621376\n",
      "SubGD iter. 312/499: loss=2.6552890354247087, w0=72.62673267326745, w1=15.971943565492673\n",
      "SubGD iter. 313/499: loss=2.6552875102302953, w0=72.63366336633676, w1=15.976412265300077\n",
      "SubGD iter. 314/499: loss=2.6553135079840917, w0=72.62673267326745, w1=15.97428616551434\n",
      "SubGD iter. 315/499: loss=2.6552898781272827, w0=72.62673267326745, w1=15.972676504793252\n",
      "SubGD iter. 316/499: loss=2.655288027407542, w0=72.62673267326745, w1=15.971066844072165\n",
      "SubGD iter. 317/499: loss=2.6552903086623254, w0=72.63366336633676, w1=15.97553554387957\n",
      "SubGD iter. 318/499: loss=2.6553121765575027, w0=72.62673267326745, w1=15.973409444093832\n",
      "SubGD iter. 319/499: loss=2.6552888701101156, w0=72.62673267326745, w1=15.971799783372745\n",
      "SubGD iter. 320/499: loss=2.6552879691725315, w0=72.63366336633676, w1=15.97626848318015\n",
      "SubGD iter. 321/499: loss=2.6553132896304246, w0=72.62673267326745, w1=15.974142383394412\n",
      "SubGD iter. 322/499: loss=2.65528971281269, w0=72.62673267326745, w1=15.972532722673325\n",
      "SubGD iter. 323/499: loss=2.6552878620929485, w0=72.62673267326745, w1=15.970923061952238\n",
      "SubGD iter. 324/499: loss=2.655290767604562, w0=72.63366336633676, w1=15.975391761759642\n",
      "SubGD iter. 325/499: loss=2.655311958203835, w0=72.62673267326745, w1=15.973265661973905\n",
      "SubGD iter. 326/499: loss=2.6552887047955225, w0=72.62673267326745, w1=15.971656001252818\n",
      "SubGD iter. 327/499: loss=2.6552884281147686, w0=72.63366336633676, w1=15.976124701060222\n",
      "SubGD iter. 328/499: loss=2.6553130712767565, w0=72.62673267326745, w1=15.973998601274484\n",
      "SubGD iter. 329/499: loss=2.6552895474980964, w0=72.62673267326745, w1=15.972388940553397\n",
      "SubGD iter. 330/499: loss=2.6552876967783554, w0=72.62673267326745, w1=15.97077927983231\n",
      "SubGD iter. 331/499: loss=2.655291226546799, w0=72.63366336633676, w1=15.975247979639715\n",
      "SubGD iter. 332/499: loss=2.6553117398501676, w0=72.62673267326745, w1=15.973121879853977\n",
      "SubGD iter. 333/499: loss=2.655288539480929, w0=72.62673267326745, w1=15.97151221913289\n",
      "SubGD iter. 334/499: loss=2.6552888870570053, w0=72.63366336633676, w1=15.975980918940294\n",
      "SubGD iter. 335/499: loss=2.6553128529230894, w0=72.62673267326745, w1=15.973854819154557\n",
      "SubGD iter. 336/499: loss=2.655289382183503, w0=72.62673267326745, w1=15.97224515843347\n",
      "SubGD iter. 337/499: loss=2.6552875314637614, w0=72.62673267326745, w1=15.970635497712383\n",
      "SubGD iter. 338/499: loss=2.6552916854890363, w0=72.63366336633676, w1=15.975104197519787\n",
      "SubGD iter. 339/499: loss=2.6553115214965004, w0=72.62673267326745, w1=15.97297809773405\n",
      "SubGD iter. 340/499: loss=2.655288374166336, w0=72.62673267326745, w1=15.971368437012963\n",
      "SubGD iter. 341/499: loss=2.6552893459992424, w0=72.63366336633676, w1=15.975837136820367\n",
      "SubGD iter. 342/499: loss=2.655312634569422, w0=72.62673267326745, w1=15.97371103703463\n",
      "SubGD iter. 343/499: loss=2.6552892168689093, w0=72.62673267326745, w1=15.972101376313542\n",
      "SubGD iter. 344/499: loss=2.6552873661491683, w0=72.62673267326745, w1=15.970491715592456\n",
      "SubGD iter. 345/499: loss=2.6552921444312725, w0=72.63366336633676, w1=15.97496041539986\n",
      "SubGD iter. 346/499: loss=2.6553113031428333, w0=72.62673267326745, w1=15.972834315614122\n",
      "SubGD iter. 347/499: loss=2.6552882088517418, w0=72.62673267326745, w1=15.971224654893035\n",
      "SubGD iter. 348/499: loss=2.6552898049414795, w0=72.63366336633676, w1=15.97569335470044\n",
      "SubGD iter. 349/499: loss=2.6553124162157546, w0=72.62673267326745, w1=15.973567254914702\n",
      "SubGD iter. 350/499: loss=2.6552890515543157, w0=72.62673267326745, w1=15.971957594193615\n",
      "SubGD iter. 351/499: loss=2.6552874654516856, w0=72.63366336633676, w1=15.976426294001019\n",
      "SubGD iter. 352/499: loss=2.6553135292886756, w0=72.62673267326745, w1=15.974300194215282\n",
      "SubGD iter. 353/499: loss=2.6552898942568897, w0=72.62673267326745, w1=15.972690533494195\n",
      "SubGD iter. 354/499: loss=2.6552880435371486, w0=72.62673267326745, w1=15.971080872773108\n",
      "SubGD iter. 355/499: loss=2.655290263883716, w0=72.63366336633676, w1=15.975549572580512\n",
      "SubGD iter. 356/499: loss=2.6553121978620875, w0=72.62673267326745, w1=15.973423472794774\n",
      "SubGD iter. 357/499: loss=2.655288886239722, w0=72.62673267326745, w1=15.971813812073687\n",
      "SubGD iter. 358/499: loss=2.655287924393922, w0=72.63366336633676, w1=15.976282511881092\n",
      "SubGD iter. 359/499: loss=2.6553133109350084, w0=72.62673267326745, w1=15.974156412095354\n",
      "SubGD iter. 360/499: loss=2.655289728942296, w0=72.62673267326745, w1=15.972546751374267\n",
      "SubGD iter. 361/499: loss=2.655287878222555, w0=72.62673267326745, w1=15.97093709065318\n",
      "SubGD iter. 362/499: loss=2.655290722825953, w0=72.63366336633676, w1=15.975405790460584\n",
      "SubGD iter. 363/499: loss=2.6553119795084195, w0=72.62673267326745, w1=15.973279690674847\n",
      "SubGD iter. 364/499: loss=2.6552887209251286, w0=72.62673267326745, w1=15.97167002995376\n",
      "SubGD iter. 365/499: loss=2.655288383336159, w0=72.63366336633676, w1=15.976138729761164\n",
      "SubGD iter. 366/499: loss=2.6553130925813413, w0=72.62673267326745, w1=15.974012629975427\n",
      "SubGD iter. 367/499: loss=2.655289563627702, w0=72.62673267326745, w1=15.97240296925434\n",
      "SubGD iter. 368/499: loss=2.655287712907962, w0=72.62673267326745, w1=15.970793308533253\n",
      "SubGD iter. 369/499: loss=2.65529118176819, w0=72.63366336633676, w1=15.975262008340657\n",
      "SubGD iter. 370/499: loss=2.655311761154752, w0=72.62673267326745, w1=15.97313590855492\n",
      "SubGD iter. 371/499: loss=2.655288555610536, w0=72.62673267326745, w1=15.971526247833832\n",
      "SubGD iter. 372/499: loss=2.655288842278396, w0=72.63366336633676, w1=15.975994947641237\n",
      "SubGD iter. 373/499: loss=2.6553128742276737, w0=72.62673267326745, w1=15.973868847855499\n",
      "SubGD iter. 374/499: loss=2.6552893983131085, w0=72.62673267326745, w1=15.972259187134412\n",
      "SubGD iter. 375/499: loss=2.6552875475933684, w0=72.62673267326745, w1=15.970649526413325\n",
      "SubGD iter. 376/499: loss=2.6552916407104266, w0=72.63366336633676, w1=15.97511822622073\n",
      "SubGD iter. 377/499: loss=2.6553115428010847, w0=72.62673267326745, w1=15.972992126434992\n",
      "SubGD iter. 378/499: loss=2.6552883902959423, w0=72.62673267326745, w1=15.971382465713905\n",
      "SubGD iter. 379/499: loss=2.655289301220633, w0=72.63366336633676, w1=15.97585116552131\n",
      "SubGD iter. 380/499: loss=2.6553126558740066, w0=72.62673267326745, w1=15.973725065735572\n",
      "SubGD iter. 381/499: loss=2.6552892329985154, w0=72.62673267326745, w1=15.972115405014485\n",
      "SubGD iter. 382/499: loss=2.655287382278775, w0=72.62673267326745, w1=15.970505744293398\n",
      "SubGD iter. 383/499: loss=2.655292099652663, w0=72.63366336633676, w1=15.974974444100802\n",
      "SubGD iter. 384/499: loss=2.6553113244474176, w0=72.62673267326745, w1=15.972848344315064\n",
      "SubGD iter. 385/499: loss=2.6552882249813483, w0=72.62673267326745, w1=15.971238683593977\n",
      "SubGD iter. 386/499: loss=2.6552897601628693, w0=72.63366336633676, w1=15.975707383401382\n",
      "SubGD iter. 387/499: loss=2.655312437520339, w0=72.62673267326745, w1=15.973581283615644\n",
      "SubGD iter. 388/499: loss=2.6552890676839214, w0=72.62673267326745, w1=15.971971622894557\n",
      "SubGD iter. 389/499: loss=2.6552874206730763, w0=72.63366336633676, w1=15.976440322701961\n",
      "SubGD iter. 390/499: loss=2.65531355059326, w0=72.62673267326745, w1=15.974314222916224\n",
      "SubGD iter. 391/499: loss=2.6552899103864958, w0=72.62673267326745, w1=15.972704562195137\n",
      "SubGD iter. 392/499: loss=2.655288059666755, w0=72.62673267326745, w1=15.97109490147405\n",
      "SubGD iter. 393/499: loss=2.6552902191051064, w0=72.63366336633676, w1=15.975563601281454\n",
      "SubGD iter. 394/499: loss=2.655312219166671, w0=72.62673267326745, w1=15.973437501495717\n",
      "SubGD iter. 395/499: loss=2.6552889023693282, w0=72.62673267326745, w1=15.97182784077463\n",
      "SubGD iter. 396/499: loss=2.6552878796153125, w0=72.63366336633676, w1=15.976296540582034\n",
      "SubGD iter. 397/499: loss=2.6553133322395928, w0=72.62673267326745, w1=15.974170440796296\n",
      "SubGD iter. 398/499: loss=2.655289745071902, w0=72.62673267326745, w1=15.97256078007521\n",
      "SubGD iter. 399/499: loss=2.655287894352161, w0=72.62673267326745, w1=15.970951119354122\n",
      "SubGD iter. 400/499: loss=2.6552906780473435, w0=72.63366336633676, w1=15.975419819161527\n",
      "SubGD iter. 401/499: loss=2.655312000813004, w0=72.62673267326745, w1=15.97329371937579\n",
      "SubGD iter. 402/499: loss=2.655288737054735, w0=72.62673267326745, w1=15.971684058654702\n",
      "SubGD iter. 403/499: loss=2.6552883385575496, w0=72.63366336633676, w1=15.976152758462106\n",
      "SubGD iter. 404/499: loss=2.6553131138859256, w0=72.62673267326745, w1=15.974026658676369\n",
      "SubGD iter. 405/499: loss=2.655289579757308, w0=72.62673267326745, w1=15.972416997955282\n",
      "SubGD iter. 406/499: loss=2.6552877290375685, w0=72.62673267326745, w1=15.970807337234195\n",
      "SubGD iter. 407/499: loss=2.65529113698958, w0=72.63366336633676, w1=15.9752760370416\n",
      "SubGD iter. 408/499: loss=2.6553117824593366, w0=72.62673267326745, w1=15.973149937255862\n",
      "SubGD iter. 409/499: loss=2.655288571740142, w0=72.62673267326745, w1=15.971540276534775\n",
      "SubGD iter. 410/499: loss=2.6552887974997863, w0=72.63366336633676, w1=15.976008976342179\n",
      "SubGD iter. 411/499: loss=2.6553128955322585, w0=72.62673267326745, w1=15.973882876556441\n",
      "SubGD iter. 412/499: loss=2.6552894144427155, w0=72.62673267326745, w1=15.972273215835354\n",
      "SubGD iter. 413/499: loss=2.6552875637229745, w0=72.62673267326745, w1=15.970663555114267\n",
      "SubGD iter. 414/499: loss=2.6552915959318177, w0=72.63366336633676, w1=15.975132254921672\n",
      "SubGD iter. 415/499: loss=2.6553115641056695, w0=72.62673267326745, w1=15.973006155135934\n",
      "SubGD iter. 416/499: loss=2.6552884064255484, w0=72.62673267326745, w1=15.971396494414847\n",
      "SubGD iter. 417/499: loss=2.6552892564420234, w0=72.63366336633676, w1=15.975865194222251\n",
      "SubGD iter. 418/499: loss=2.6553126771785904, w0=72.62673267326745, w1=15.973739094436514\n",
      "SubGD iter. 419/499: loss=2.655289249128122, w0=72.62673267326745, w1=15.972129433715427\n",
      "SubGD iter. 420/499: loss=2.6552873984083813, w0=72.62673267326745, w1=15.97051977299434\n",
      "SubGD iter. 421/499: loss=2.6552920548740544, w0=72.63366336633676, w1=15.974988472801744\n",
      "SubGD iter. 422/499: loss=2.655311345752002, w0=72.62673267326745, w1=15.972862373016007\n",
      "SubGD iter. 423/499: loss=2.6552882411109544, w0=72.62673267326745, w1=15.97125271229492\n",
      "SubGD iter. 424/499: loss=2.6552897153842605, w0=72.63366336633676, w1=15.975721412102324\n",
      "SubGD iter. 425/499: loss=2.655312458824923, w0=72.62673267326745, w1=15.973595312316586\n",
      "SubGD iter. 426/499: loss=2.655289083813528, w0=72.62673267326745, w1=15.9719856515955\n",
      "SubGD iter. 427/499: loss=2.6552873758944666, w0=72.63366336633676, w1=15.976454351402904\n",
      "SubGD iter. 428/499: loss=2.6553135718978447, w0=72.62673267326745, w1=15.974328251617166\n",
      "SubGD iter. 429/499: loss=2.6552899265161023, w0=72.62673267326745, w1=15.97271859089608\n",
      "SubGD iter. 430/499: loss=2.655288075796361, w0=72.62673267326745, w1=15.971108930174992\n",
      "SubGD iter. 431/499: loss=2.6552901743264967, w0=72.63366336633676, w1=15.975577629982396\n",
      "SubGD iter. 432/499: loss=2.6553122404712557, w0=72.62673267326745, w1=15.973451530196659\n",
      "SubGD iter. 433/499: loss=2.655288918498935, w0=72.62673267326745, w1=15.971841869475572\n",
      "SubGD iter. 434/499: loss=2.6552878348367037, w0=72.63366336633676, w1=15.976310569282976\n",
      "SubGD iter. 435/499: loss=2.655313353544177, w0=72.62673267326745, w1=15.974184469497239\n",
      "SubGD iter. 436/499: loss=2.6552897612015087, w0=72.62673267326745, w1=15.972574808776152\n",
      "SubGD iter. 437/499: loss=2.6552879104817677, w0=72.62673267326745, w1=15.970965148055065\n",
      "SubGD iter. 438/499: loss=2.655290633268734, w0=72.63366336633676, w1=15.975433847862469\n",
      "SubGD iter. 439/499: loss=2.6553120221175885, w0=72.62673267326745, w1=15.973307748076731\n",
      "SubGD iter. 440/499: loss=2.6552887531843417, w0=72.62673267326745, w1=15.971698087355644\n",
      "SubGD iter. 441/499: loss=2.6552882937789404, w0=72.63366336633676, w1=15.976166787163049\n",
      "SubGD iter. 442/499: loss=2.65531313519051, w0=72.62673267326745, w1=15.974040687377311\n",
      "SubGD iter. 443/499: loss=2.6552895958869147, w0=72.62673267326745, w1=15.972431026656224\n",
      "SubGD iter. 444/499: loss=2.655287745167174, w0=72.62673267326745, w1=15.970821365935137\n",
      "SubGD iter. 445/499: loss=2.655291092210971, w0=72.63366336633676, w1=15.975290065742541\n",
      "SubGD iter. 446/499: loss=2.655311803763921, w0=72.62673267326745, w1=15.973163965956804\n",
      "SubGD iter. 447/499: loss=2.655288587869748, w0=72.62673267326745, w1=15.971554305235717\n",
      "SubGD iter. 448/499: loss=2.655288752721177, w0=72.63366336633676, w1=15.976023005043121\n",
      "SubGD iter. 449/499: loss=2.655312916836842, w0=72.62673267326745, w1=15.973896905257384\n",
      "SubGD iter. 450/499: loss=2.6552894305723216, w0=72.62673267326745, w1=15.972287244536297\n",
      "SubGD iter. 451/499: loss=2.655287579852581, w0=72.62673267326745, w1=15.97067758381521\n",
      "SubGD iter. 452/499: loss=2.6552915511532076, w0=72.63366336633676, w1=15.975146283622614\n",
      "SubGD iter. 453/499: loss=2.6553115854102534, w0=72.62673267326745, w1=15.973020183836876\n",
      "SubGD iter. 454/499: loss=2.655288422555155, w0=72.62673267326745, w1=15.97141052311579\n",
      "SubGD iter. 455/499: loss=2.655289211663414, w0=72.63366336633676, w1=15.975879222923194\n",
      "SubGD iter. 456/499: loss=2.6553126984831747, w0=72.62673267326745, w1=15.973753123137456\n",
      "SubGD iter. 457/499: loss=2.655289265257728, w0=72.62673267326745, w1=15.97214346241637\n",
      "SubGD iter. 458/499: loss=2.655287414537988, w0=72.62673267326745, w1=15.970533801695282\n",
      "SubGD iter. 459/499: loss=2.6552920100954442, w0=72.63366336633676, w1=15.975002501502686\n",
      "SubGD iter. 460/499: loss=2.6553113670565858, w0=72.62673267326745, w1=15.972876401716949\n",
      "SubGD iter. 461/499: loss=2.6552882572405605, w0=72.62673267326745, w1=15.971266740995862\n",
      "SubGD iter. 462/499: loss=2.6552896706056512, w0=72.63366336633676, w1=15.975735440803266\n",
      "SubGD iter. 463/499: loss=2.6553124801295076, w0=72.62673267326745, w1=15.973609341017529\n",
      "SubGD iter. 464/499: loss=2.655289099943134, w0=72.62673267326745, w1=15.971999680296442\n",
      "SubGD iter. 465/499: loss=2.6552873311158574, w0=72.63366336633676, w1=15.976468380103846\n",
      "SubGD iter. 466/499: loss=2.6553135932024294, w0=72.62673267326745, w1=15.974342280318108\n",
      "SubGD iter. 467/499: loss=2.655289942645708, w0=72.62673267326745, w1=15.972732619597021\n",
      "SubGD iter. 468/499: loss=2.655288091925968, w0=72.62673267326745, w1=15.971122958875934\n",
      "SubGD iter. 469/499: loss=2.6552901295478875, w0=72.63366336633676, w1=15.975591658683339\n",
      "SubGD iter. 470/499: loss=2.65531226177584, w0=72.62673267326745, w1=15.973465558897601\n",
      "SubGD iter. 471/499: loss=2.6552889346285413, w0=72.62673267326745, w1=15.971855898176514\n",
      "SubGD iter. 472/499: loss=2.6552877900580945, w0=72.63366336633676, w1=15.976324597983918\n",
      "SubGD iter. 473/499: loss=2.655313374848762, w0=72.62673267326745, w1=15.97419849819818\n",
      "SubGD iter. 474/499: loss=2.6552897773311153, w0=72.62673267326745, w1=15.972588837477094\n",
      "SubGD iter. 475/499: loss=2.6552879266113742, w0=72.62673267326745, w1=15.970979176756007\n",
      "SubGD iter. 476/499: loss=2.655290588490124, w0=72.63366336633676, w1=15.975447876563411\n",
      "SubGD iter. 477/499: loss=2.655312043422172, w0=72.62673267326745, w1=15.973321776777674\n",
      "SubGD iter. 478/499: loss=2.6552887693139477, w0=72.62673267326745, w1=15.971712116056587\n",
      "SubGD iter. 479/499: loss=2.6552882490003316, w0=72.63366336633676, w1=15.97618081586399\n",
      "SubGD iter. 480/499: loss=2.655313156495094, w0=72.62673267326745, w1=15.974054716078253\n",
      "SubGD iter. 481/499: loss=2.6552896120165213, w0=72.62673267326745, w1=15.972445055357166\n",
      "SubGD iter. 482/499: loss=2.6552877612967802, w0=72.62673267326745, w1=15.97083539463608\n",
      "SubGD iter. 483/499: loss=2.6552910474323617, w0=72.63366336633676, w1=15.975304094443484\n",
      "SubGD iter. 484/499: loss=2.6553118250685053, w0=72.62673267326745, w1=15.973177994657746\n",
      "SubGD iter. 485/499: loss=2.6552886039993546, w0=72.62673267326745, w1=15.97156833393666\n",
      "SubGD iter. 486/499: loss=2.6552887079425678, w0=72.63366336633676, w1=15.976037033744063\n",
      "SubGD iter. 487/499: loss=2.6553129381414267, w0=72.62673267326745, w1=15.973910933958326\n",
      "SubGD iter. 488/499: loss=2.6552894467019277, w0=72.62673267326745, w1=15.972301273237239\n",
      "SubGD iter. 489/499: loss=2.6552875959821876, w0=72.62673267326745, w1=15.970691612516152\n",
      "SubGD iter. 490/499: loss=2.6552915063745983, w0=72.63366336633676, w1=15.975160312323556\n",
      "SubGD iter. 491/499: loss=2.6553116067148377, w0=72.62673267326745, w1=15.973034212537819\n",
      "SubGD iter. 492/499: loss=2.6552884386847606, w0=72.62673267326745, w1=15.971424551816732\n",
      "SubGD iter. 493/499: loss=2.6552891668848044, w0=72.63366336633676, w1=15.975893251624136\n",
      "SubGD iter. 494/499: loss=2.655312719787759, w0=72.62673267326745, w1=15.973767151838398\n",
      "SubGD iter. 495/499: loss=2.6552892813873346, w0=72.62673267326745, w1=15.972157491117311\n",
      "SubGD iter. 496/499: loss=2.6552874306675935, w0=72.62673267326745, w1=15.970547830396224\n",
      "SubGD iter. 497/499: loss=2.6552919653168354, w0=72.63366336633676, w1=15.975016530203629\n",
      "SubGD iter. 498/499: loss=2.6553113883611705, w0=72.62673267326745, w1=15.972890430417891\n",
      "SubGD iter. 499/499: loss=2.6552882733701675, w0=72.62673267326745, w1=15.971280769696804\n",
      "SubGD: execution time=0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ddc17259464c0fb8eaf44156d3ada1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        total_batches = len(y) // batch_size\n",
    "        avg_loss = 0\n",
    "        for (batch_y, batch_tx) in batch_iter(y, tx, batch_size=batch_size, num_batches=total_batches):\n",
    "            grad = compute_subgradient_mae(batch_y, batch_tx, w)\n",
    "            avg_loss += compute_loss(batch_y, batch_tx, w, loss=mae)\n",
    "            w = w - gamma * grad\n",
    "        avg_loss /= total_batches\n",
    "        losses.append(avg_loss)\n",
    "        ws.append(w)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=avg_loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=11.774982694861292, w0=71.40000000000013, w1=14.642159769638003\n",
      "SubSGD iter. 1/499: loss=2.8929556370388707, w0=72.80000000000014, w1=16.261949692598613\n",
      "SubSGD iter. 2/499: loss=2.8750138384794233, w0=72.80000000000014, w1=16.308157089447793\n",
      "SubSGD iter. 3/499: loss=2.8467595172837843, w0=72.80000000000014, w1=14.342928248080968\n",
      "SubSGD iter. 4/499: loss=2.7889771272093284, w0=75.60000000000015, w1=11.152234991876064\n",
      "SubSGD iter. 5/499: loss=2.942604972214299, w0=72.80000000000014, w1=17.325745647554413\n",
      "SubSGD iter. 6/499: loss=2.8027114705473206, w0=71.40000000000013, w1=17.046078983868874\n",
      "SubSGD iter. 7/499: loss=2.856195099000049, w0=75.60000000000015, w1=17.618696452114488\n",
      "SubSGD iter. 8/499: loss=2.829495988270998, w0=70.00000000000013, w1=14.172180752920225\n",
      "SubSGD iter. 9/499: loss=2.908552053362483, w0=71.40000000000013, w1=13.541539226831873\n",
      "SubSGD iter. 10/499: loss=2.8165569738456493, w0=70.00000000000013, w1=15.555819955076364\n",
      "SubSGD iter. 11/499: loss=2.8867997023177785, w0=72.80000000000014, w1=15.340678592807079\n",
      "SubSGD iter. 12/499: loss=2.8413498765929353, w0=71.40000000000013, w1=15.009365882423776\n",
      "SubSGD iter. 13/499: loss=2.910133344367057, w0=71.40000000000013, w1=17.91405276121965\n",
      "SubSGD iter. 14/499: loss=2.9037337930051073, w0=70.00000000000013, w1=16.65539118337988\n",
      "SubSGD iter. 15/499: loss=2.7530170145380017, w0=71.40000000000013, w1=15.79594014903095\n",
      "SubSGD iter. 16/499: loss=2.8694231885077652, w0=72.80000000000014, w1=16.178891797023503\n",
      "SubSGD iter. 17/499: loss=2.7874796610647, w0=75.60000000000015, w1=13.83988281566743\n",
      "SubSGD iter. 18/499: loss=2.8871820334995237, w0=72.80000000000014, w1=16.723089199847198\n",
      "SubSGD iter. 19/499: loss=2.911455513077517, w0=71.40000000000013, w1=15.659184995472364\n",
      "SubSGD iter. 20/499: loss=2.855841999838448, w0=71.40000000000013, w1=18.93969929393516\n",
      "SubSGD iter. 21/499: loss=2.8208838491716626, w0=71.40000000000013, w1=16.770305427300265\n",
      "SubSGD iter. 22/499: loss=2.9044276236135107, w0=75.60000000000015, w1=16.896061235885767\n",
      "SubSGD iter. 23/499: loss=2.8754288267053245, w0=72.80000000000014, w1=17.854690978826568\n",
      "SubSGD iter. 24/499: loss=2.8763575824548657, w0=77.00000000000016, w1=15.265596553352344\n",
      "SubSGD iter. 25/499: loss=2.838838470807896, w0=71.40000000000013, w1=19.93824562312365\n",
      "SubSGD iter. 26/499: loss=2.8649844201462216, w0=71.40000000000013, w1=15.992093110514256\n",
      "SubSGD iter. 27/499: loss=2.8683905598399986, w0=71.40000000000013, w1=16.05990800434663\n",
      "SubSGD iter. 28/499: loss=2.912287297163844, w0=72.80000000000014, w1=13.132065370640095\n",
      "SubSGD iter. 29/499: loss=2.8865221824844727, w0=70.00000000000013, w1=16.233206956770367\n",
      "SubSGD iter. 30/499: loss=2.8178763741560693, w0=71.40000000000013, w1=18.816637899188557\n",
      "SubSGD iter. 31/499: loss=2.828830740339347, w0=71.40000000000013, w1=18.41613763664538\n",
      "SubSGD iter. 32/499: loss=2.8951347034169053, w0=70.00000000000013, w1=15.007046558895686\n",
      "SubSGD iter. 33/499: loss=2.8503672358731182, w0=74.20000000000014, w1=17.268353146813244\n",
      "SubSGD iter. 34/499: loss=2.9235990728517085, w0=72.80000000000014, w1=14.037661633849956\n",
      "SubSGD iter. 35/499: loss=2.887803297063781, w0=71.40000000000013, w1=17.25386654792896\n",
      "SubSGD iter. 36/499: loss=2.8883473971879003, w0=71.40000000000013, w1=16.12419962850668\n",
      "SubSGD iter. 37/499: loss=2.7970282021375255, w0=71.40000000000013, w1=14.607408165173528\n",
      "SubSGD iter. 38/499: loss=2.845461841909939, w0=71.40000000000013, w1=16.49759705463587\n",
      "SubSGD iter. 39/499: loss=2.877650474051858, w0=71.40000000000013, w1=16.839433696804647\n",
      "SubSGD iter. 40/499: loss=2.776229495806564, w0=77.00000000000016, w1=10.883881673803876\n",
      "SubSGD iter. 41/499: loss=2.8638196077472418, w0=71.40000000000013, w1=15.796061916194732\n",
      "SubSGD iter. 42/499: loss=2.829753113258711, w0=72.80000000000014, w1=14.822590994395451\n",
      "SubSGD iter. 43/499: loss=2.8312524531287573, w0=71.40000000000013, w1=14.235400737487476\n",
      "SubSGD iter. 44/499: loss=2.8882566723151633, w0=71.40000000000013, w1=19.227898731211365\n",
      "SubSGD iter. 45/499: loss=2.812242986541598, w0=71.40000000000013, w1=16.602399518645015\n",
      "SubSGD iter. 46/499: loss=2.8370552168811294, w0=68.60000000000012, w1=15.611999128515013\n",
      "SubSGD iter. 47/499: loss=2.909355458922364, w0=72.80000000000014, w1=15.147535205231792\n",
      "SubSGD iter. 48/499: loss=2.85101881082374, w0=70.00000000000013, w1=16.362103284710702\n",
      "SubSGD iter. 49/499: loss=2.8111094187297994, w0=75.60000000000015, w1=14.287126117723272\n",
      "SubSGD iter. 50/499: loss=2.828532228318985, w0=74.20000000000014, w1=16.42090029043625\n",
      "SubSGD iter. 51/499: loss=2.915734291315339, w0=72.80000000000014, w1=17.92238404148638\n",
      "SubSGD iter. 52/499: loss=2.8328601397885405, w0=75.60000000000015, w1=15.420799030320254\n",
      "SubSGD iter. 53/499: loss=2.83991565460094, w0=72.80000000000014, w1=16.994651566511198\n",
      "SubSGD iter. 54/499: loss=2.936584891217605, w0=72.80000000000014, w1=16.18522367969179\n",
      "SubSGD iter. 55/499: loss=2.922625671880433, w0=74.20000000000014, w1=12.780907664867946\n",
      "SubSGD iter. 56/499: loss=2.939181180911814, w0=71.40000000000013, w1=16.20839050704172\n",
      "SubSGD iter. 57/499: loss=2.777420715518733, w0=74.20000000000014, w1=12.454711626667953\n",
      "SubSGD iter. 58/499: loss=2.92741984563362, w0=71.40000000000013, w1=14.601056963931\n",
      "SubSGD iter. 59/499: loss=2.875953396994795, w0=70.00000000000013, w1=16.842726617247656\n",
      "SubSGD iter. 60/499: loss=2.736577101685735, w0=71.40000000000013, w1=15.511347508252683\n",
      "SubSGD iter. 61/499: loss=2.8495002600767205, w0=77.00000000000016, w1=12.14357112494347\n",
      "SubSGD iter. 62/499: loss=2.87978620166724, w0=74.20000000000014, w1=15.653700933738138\n",
      "SubSGD iter. 63/499: loss=2.880220751862122, w0=74.20000000000014, w1=16.86531296976456\n",
      "SubSGD iter. 64/499: loss=2.8426500292741594, w0=75.60000000000015, w1=15.302861207067247\n",
      "SubSGD iter. 65/499: loss=2.7576742763835487, w0=72.80000000000014, w1=17.171748587544865\n",
      "SubSGD iter. 66/499: loss=2.8718502309487985, w0=75.60000000000015, w1=14.316895573554278\n",
      "SubSGD iter. 67/499: loss=2.824018087520007, w0=72.80000000000014, w1=17.370101720498408\n",
      "SubSGD iter. 68/499: loss=2.813555836339146, w0=71.40000000000013, w1=16.434357953860943\n",
      "SubSGD iter. 69/499: loss=2.802172283349493, w0=72.80000000000014, w1=15.495666834442343\n",
      "SubSGD iter. 70/499: loss=2.855408157640747, w0=72.80000000000014, w1=15.370715577453794\n",
      "SubSGD iter. 71/499: loss=2.9252776547760595, w0=71.40000000000013, w1=16.139471236195067\n",
      "SubSGD iter. 72/499: loss=2.858956391414774, w0=72.80000000000014, w1=15.536743624959216\n",
      "SubSGD iter. 73/499: loss=2.7331168496865, w0=75.60000000000015, w1=17.386576748172555\n",
      "SubSGD iter. 74/499: loss=2.91090554413406, w0=72.80000000000014, w1=17.932537350553368\n",
      "SubSGD iter. 75/499: loss=2.937292806931074, w0=70.00000000000013, w1=15.63020935757051\n",
      "SubSGD iter. 76/499: loss=2.869708550295677, w0=71.40000000000013, w1=15.638099825402993\n",
      "SubSGD iter. 77/499: loss=2.857608382650183, w0=72.80000000000014, w1=17.396253363375294\n",
      "SubSGD iter. 78/499: loss=2.8111959428863456, w0=71.40000000000013, w1=15.3134197872905\n",
      "SubSGD iter. 79/499: loss=2.872754863213922, w0=72.80000000000014, w1=17.7263861230618\n",
      "SubSGD iter. 80/499: loss=2.8610327423234043, w0=71.40000000000013, w1=15.210674601140571\n",
      "SubSGD iter. 81/499: loss=2.8762211205862473, w0=74.20000000000014, w1=15.73337264846406\n",
      "SubSGD iter. 82/499: loss=2.8030391102850496, w0=74.20000000000014, w1=18.68239704761186\n",
      "SubSGD iter. 83/499: loss=2.831906289909164, w0=72.80000000000014, w1=15.775532891512249\n",
      "SubSGD iter. 84/499: loss=2.877402569508975, w0=72.80000000000014, w1=16.095161683353485\n",
      "SubSGD iter. 85/499: loss=2.8531472298848466, w0=71.40000000000013, w1=15.540131904794675\n",
      "SubSGD iter. 86/499: loss=2.8639907707850023, w0=71.40000000000013, w1=16.252457764556272\n",
      "SubSGD iter. 87/499: loss=2.8857898889210216, w0=74.20000000000014, w1=16.170147405025627\n",
      "SubSGD iter. 88/499: loss=2.878275190608264, w0=74.20000000000014, w1=17.127283002522557\n",
      "SubSGD iter. 89/499: loss=2.7733462145137144, w0=71.40000000000013, w1=16.35389615260548\n",
      "SubSGD iter. 90/499: loss=2.871759799189037, w0=71.40000000000013, w1=17.995585307635547\n",
      "SubSGD iter. 91/499: loss=2.807902251410097, w0=72.80000000000014, w1=13.872030968448183\n",
      "SubSGD iter. 92/499: loss=2.8603981151204243, w0=72.80000000000014, w1=16.868338458087074\n",
      "SubSGD iter. 93/499: loss=2.8565908082628924, w0=72.80000000000014, w1=15.599683319569568\n",
      "SubSGD iter. 94/499: loss=2.8629685505532705, w0=72.80000000000014, w1=15.992740525862384\n",
      "SubSGD iter. 95/499: loss=2.8042463591445106, w0=72.80000000000014, w1=14.933269004524881\n",
      "SubSGD iter. 96/499: loss=2.8468489879445817, w0=72.80000000000014, w1=15.797437644395737\n",
      "SubSGD iter. 97/499: loss=2.8537020845747043, w0=72.80000000000014, w1=15.125379498177004\n",
      "SubSGD iter. 98/499: loss=2.843839405763973, w0=72.80000000000014, w1=16.187914886493324\n",
      "SubSGD iter. 99/499: loss=2.827631182704181, w0=74.20000000000014, w1=12.041200545820626\n",
      "SubSGD iter. 100/499: loss=2.8733071293231025, w0=74.20000000000014, w1=18.25383535887105\n",
      "SubSGD iter. 101/499: loss=2.7842152024833537, w0=72.80000000000014, w1=16.54739055974114\n",
      "SubSGD iter. 102/499: loss=2.862857926927232, w0=72.80000000000014, w1=15.73700309005621\n",
      "SubSGD iter. 103/499: loss=2.8200723285365705, w0=72.80000000000014, w1=19.350842171516096\n",
      "SubSGD iter. 104/499: loss=2.88251397801458, w0=71.40000000000013, w1=15.83583093207076\n",
      "SubSGD iter. 105/499: loss=2.8299188302213136, w0=74.20000000000014, w1=20.106131891306553\n",
      "SubSGD iter. 106/499: loss=2.808474169572618, w0=74.20000000000014, w1=12.810439156454182\n",
      "SubSGD iter. 107/499: loss=2.8716521876277366, w0=71.40000000000013, w1=15.62957672367177\n",
      "SubSGD iter. 108/499: loss=2.8532493765985296, w0=70.00000000000013, w1=15.485391315817258\n",
      "SubSGD iter. 109/499: loss=2.829169339581725, w0=70.00000000000013, w1=17.000691257752504\n",
      "SubSGD iter. 110/499: loss=2.9162955617859843, w0=74.20000000000014, w1=17.548293555508142\n",
      "SubSGD iter. 111/499: loss=2.7778012143473667, w0=71.40000000000013, w1=16.010686289165964\n",
      "SubSGD iter. 112/499: loss=2.8477160220228015, w0=74.20000000000014, w1=17.366011712431686\n",
      "SubSGD iter. 113/499: loss=2.8586442705057307, w0=71.40000000000013, w1=14.899442021420803\n",
      "SubSGD iter. 114/499: loss=2.8869304822256487, w0=74.20000000000014, w1=18.137869409917826\n",
      "SubSGD iter. 115/499: loss=2.8296118153824636, w0=71.40000000000013, w1=15.255640198497714\n",
      "SubSGD iter. 116/499: loss=2.8853041098849945, w0=71.40000000000013, w1=11.2896225016416\n",
      "SubSGD iter. 117/499: loss=2.9173086604828797, w0=71.40000000000013, w1=15.44355433186213\n",
      "SubSGD iter. 118/499: loss=2.837474938760209, w0=74.20000000000014, w1=16.668077187016788\n",
      "SubSGD iter. 119/499: loss=2.833380502477803, w0=70.00000000000013, w1=14.803927326086916\n",
      "SubSGD iter. 120/499: loss=2.8756937361496138, w0=74.20000000000014, w1=18.13921218442686\n",
      "SubSGD iter. 121/499: loss=2.829895335851676, w0=71.40000000000013, w1=14.07149194074136\n",
      "SubSGD iter. 122/499: loss=2.7984237301364407, w0=72.80000000000014, w1=13.733526185926555\n",
      "SubSGD iter. 123/499: loss=2.8108998728911803, w0=72.80000000000014, w1=17.30011973501423\n",
      "SubSGD iter. 124/499: loss=2.8675872664579067, w0=71.40000000000013, w1=14.336642967220465\n",
      "SubSGD iter. 125/499: loss=2.9082293485155737, w0=74.20000000000014, w1=15.53753528704694\n",
      "SubSGD iter. 126/499: loss=2.882307605057366, w0=71.40000000000013, w1=16.45108904547835\n",
      "SubSGD iter. 127/499: loss=2.7797178292196167, w0=71.40000000000013, w1=17.65639751679906\n",
      "SubSGD iter. 128/499: loss=2.791832748797575, w0=70.00000000000013, w1=16.860941722414328\n",
      "SubSGD iter. 129/499: loss=2.804273203698882, w0=74.20000000000014, w1=13.006302302101798\n",
      "SubSGD iter. 130/499: loss=2.918313513842712, w0=74.20000000000014, w1=17.968070002570848\n",
      "SubSGD iter. 131/499: loss=2.8619657691138456, w0=74.20000000000014, w1=17.042498199352085\n",
      "SubSGD iter. 132/499: loss=2.9147460937467358, w0=74.20000000000014, w1=15.91409436566835\n",
      "SubSGD iter. 133/499: loss=2.9132996448689883, w0=72.80000000000014, w1=17.123418186325733\n",
      "SubSGD iter. 134/499: loss=2.7600530075609733, w0=70.00000000000013, w1=15.566376457121223\n",
      "SubSGD iter. 135/499: loss=2.941611584289847, w0=71.40000000000013, w1=16.588363290648797\n",
      "SubSGD iter. 136/499: loss=2.8435254171658686, w0=71.40000000000013, w1=17.18761907928938\n",
      "SubSGD iter. 137/499: loss=2.8590626679321747, w0=74.20000000000014, w1=15.971338019248186\n",
      "SubSGD iter. 138/499: loss=2.879655746770869, w0=74.20000000000014, w1=13.045740754627507\n",
      "SubSGD iter. 139/499: loss=2.7992779209647156, w0=72.80000000000014, w1=13.329614577955702\n",
      "SubSGD iter. 140/499: loss=2.803746900505941, w0=70.00000000000013, w1=14.820444817185912\n",
      "SubSGD iter. 141/499: loss=2.856849929057242, w0=71.40000000000013, w1=14.793636347157129\n",
      "SubSGD iter. 142/499: loss=2.893628926292516, w0=71.40000000000013, w1=14.720231768207519\n",
      "SubSGD iter. 143/499: loss=2.824996911647193, w0=74.20000000000014, w1=17.620610204434257\n",
      "SubSGD iter. 144/499: loss=2.813227047079175, w0=74.20000000000014, w1=14.551325450453636\n",
      "SubSGD iter. 145/499: loss=2.8844734991355274, w0=71.40000000000013, w1=17.055105737591106\n",
      "SubSGD iter. 146/499: loss=2.8847852491050734, w0=75.60000000000015, w1=16.418819404814666\n",
      "SubSGD iter. 147/499: loss=2.886815269461881, w0=74.20000000000014, w1=18.04440978244249\n",
      "SubSGD iter. 148/499: loss=2.875860868958455, w0=70.00000000000013, w1=14.033415716531799\n",
      "SubSGD iter. 149/499: loss=2.7870340001352565, w0=71.40000000000013, w1=15.475747223379004\n",
      "SubSGD iter. 150/499: loss=2.826833900635241, w0=72.80000000000014, w1=15.865606154899709\n",
      "SubSGD iter. 151/499: loss=2.843865882220364, w0=74.20000000000014, w1=16.695012913662687\n",
      "SubSGD iter. 152/499: loss=2.883883459493735, w0=72.80000000000014, w1=17.0673579567536\n",
      "SubSGD iter. 153/499: loss=2.8964098940712386, w0=72.80000000000014, w1=15.289292611905761\n",
      "SubSGD iter. 154/499: loss=2.85139781226534, w0=72.80000000000014, w1=18.65360932632805\n",
      "SubSGD iter. 155/499: loss=2.9229085110204585, w0=72.80000000000014, w1=18.739607867234533\n",
      "SubSGD iter. 156/499: loss=2.8130529342904227, w0=72.80000000000014, w1=14.944334226212483\n",
      "SubSGD iter. 157/499: loss=2.8100752448721047, w0=72.80000000000014, w1=16.930036754777763\n",
      "SubSGD iter. 158/499: loss=2.772586650821927, w0=71.40000000000013, w1=16.991166516239186\n",
      "SubSGD iter. 159/499: loss=2.818125523005781, w0=72.80000000000014, w1=14.747727405286925\n",
      "SubSGD iter. 160/499: loss=2.838482247095844, w0=72.80000000000014, w1=17.097440467675902\n",
      "SubSGD iter. 161/499: loss=2.8790725103935064, w0=72.80000000000014, w1=16.47451677395112\n",
      "SubSGD iter. 162/499: loss=2.898759299930318, w0=71.40000000000013, w1=14.610078352335563\n",
      "SubSGD iter. 163/499: loss=2.871701669383981, w0=72.80000000000014, w1=14.846070829416371\n",
      "SubSGD iter. 164/499: loss=2.8134748136575927, w0=75.60000000000015, w1=16.79206680008038\n",
      "SubSGD iter. 165/499: loss=2.8853852727901814, w0=72.80000000000014, w1=15.71151492772657\n",
      "SubSGD iter. 166/499: loss=2.938676858393583, w0=71.40000000000013, w1=15.850692774861042\n",
      "SubSGD iter. 167/499: loss=2.8440315157178317, w0=70.00000000000013, w1=15.564418180875215\n",
      "SubSGD iter. 168/499: loss=2.8931230954610516, w0=72.80000000000014, w1=15.481862810933201\n",
      "SubSGD iter. 169/499: loss=2.8272420897004733, w0=71.40000000000013, w1=12.34713755041568\n",
      "SubSGD iter. 170/499: loss=2.834912673696473, w0=71.40000000000013, w1=10.666365587291528\n",
      "SubSGD iter. 171/499: loss=2.932456098264054, w0=75.60000000000015, w1=16.2532266343853\n",
      "SubSGD iter. 172/499: loss=2.9139723252520517, w0=72.80000000000014, w1=16.03426001001318\n",
      "SubSGD iter. 173/499: loss=2.762995171659921, w0=72.80000000000014, w1=16.724011977313637\n",
      "SubSGD iter. 174/499: loss=2.87964151033596, w0=75.60000000000015, w1=11.708525811652901\n",
      "SubSGD iter. 175/499: loss=2.872242068480159, w0=72.80000000000014, w1=15.466041571747047\n",
      "SubSGD iter. 176/499: loss=2.7795764545066235, w0=74.20000000000014, w1=14.109175123461482\n",
      "SubSGD iter. 177/499: loss=2.8488912144737832, w0=74.20000000000014, w1=17.69943465733937\n",
      "SubSGD iter. 178/499: loss=2.7677440845281396, w0=74.20000000000014, w1=20.552347394795067\n",
      "SubSGD iter. 179/499: loss=2.9141567367567847, w0=74.20000000000014, w1=15.049445914904005\n",
      "SubSGD iter. 180/499: loss=2.73658504903265, w0=74.20000000000014, w1=15.633907131938358\n",
      "SubSGD iter. 181/499: loss=2.8154401246809826, w0=70.00000000000013, w1=15.542471132934189\n",
      "SubSGD iter. 182/499: loss=2.8753741784122835, w0=71.40000000000013, w1=14.551039603722344\n",
      "SubSGD iter. 183/499: loss=2.900496729995834, w0=72.80000000000014, w1=12.646547758169394\n",
      "SubSGD iter. 184/499: loss=2.7836090004246232, w0=75.60000000000015, w1=14.731280599288045\n",
      "SubSGD iter. 185/499: loss=2.8174976254339534, w0=72.80000000000014, w1=15.455148185564811\n",
      "SubSGD iter. 186/499: loss=2.794064864063049, w0=72.80000000000014, w1=15.929165305986064\n",
      "SubSGD iter. 187/499: loss=2.815607631361009, w0=74.20000000000014, w1=14.51327017044186\n",
      "SubSGD iter. 188/499: loss=2.828870183611678, w0=74.20000000000014, w1=16.67973596189571\n",
      "SubSGD iter. 189/499: loss=2.837862171693681, w0=72.80000000000014, w1=15.153268281811654\n",
      "SubSGD iter. 190/499: loss=2.83275051573354, w0=71.40000000000013, w1=15.528513794911806\n",
      "SubSGD iter. 191/499: loss=2.8684581137516845, w0=72.80000000000014, w1=15.624420491805308\n",
      "SubSGD iter. 192/499: loss=2.839654937776271, w0=71.40000000000013, w1=18.2655780499046\n",
      "SubSGD iter. 193/499: loss=2.8241699521751804, w0=74.20000000000014, w1=17.63998191855277\n",
      "SubSGD iter. 194/499: loss=2.8469586635993913, w0=71.40000000000013, w1=17.2203720689813\n",
      "SubSGD iter. 195/499: loss=2.819899530179166, w0=71.40000000000013, w1=18.85994062383033\n",
      "SubSGD iter. 196/499: loss=2.874271586664418, w0=71.40000000000013, w1=15.596128859659922\n",
      "SubSGD iter. 197/499: loss=2.845412023693638, w0=71.40000000000013, w1=16.186815543745922\n",
      "SubSGD iter. 198/499: loss=2.907889242044498, w0=71.40000000000013, w1=16.153072320694257\n",
      "SubSGD iter. 199/499: loss=2.8024291307881315, w0=75.60000000000015, w1=17.101936681083327\n",
      "SubSGD iter. 200/499: loss=2.920843992956451, w0=71.40000000000013, w1=16.504971095127807\n",
      "SubSGD iter. 201/499: loss=2.8579466665013475, w0=72.80000000000014, w1=14.627742623153361\n",
      "SubSGD iter. 202/499: loss=2.8028749006172347, w0=75.60000000000015, w1=13.74388361059598\n",
      "SubSGD iter. 203/499: loss=2.832872695296856, w0=75.60000000000015, w1=16.389915499739317\n",
      "SubSGD iter. 204/499: loss=2.8875568889197347, w0=71.40000000000013, w1=14.677976217032386\n",
      "SubSGD iter. 205/499: loss=2.8624513561373184, w0=72.80000000000014, w1=11.652615512394663\n",
      "SubSGD iter. 206/499: loss=2.836120813140355, w0=71.40000000000013, w1=14.2402853654745\n",
      "SubSGD iter. 207/499: loss=2.837042893864796, w0=72.80000000000014, w1=18.885561730532032\n",
      "SubSGD iter. 208/499: loss=2.830520028220991, w0=70.00000000000013, w1=16.785861647759045\n",
      "SubSGD iter. 209/499: loss=2.8692015786818317, w0=72.80000000000014, w1=15.901934491133456\n",
      "SubSGD iter. 210/499: loss=2.7824211905980296, w0=71.40000000000013, w1=15.60904214339542\n",
      "SubSGD iter. 211/499: loss=2.879028027382265, w0=71.40000000000013, w1=15.019307946547343\n",
      "SubSGD iter. 212/499: loss=2.955662025572917, w0=72.80000000000014, w1=16.415054550107754\n",
      "SubSGD iter. 213/499: loss=2.8572201826546264, w0=71.40000000000013, w1=13.969540951679845\n",
      "SubSGD iter. 214/499: loss=2.8136667596866105, w0=72.80000000000014, w1=17.85975009842666\n",
      "SubSGD iter. 215/499: loss=2.848987229417934, w0=71.40000000000013, w1=17.89456650858934\n",
      "SubSGD iter. 216/499: loss=2.8268280739605034, w0=70.00000000000013, w1=14.35085038301067\n",
      "SubSGD iter. 217/499: loss=2.838944543762914, w0=74.20000000000014, w1=15.133081219639894\n",
      "SubSGD iter. 218/499: loss=2.889399388672462, w0=74.20000000000014, w1=15.43838575748284\n",
      "SubSGD iter. 219/499: loss=2.8690461184866494, w0=71.40000000000013, w1=17.45247197387216\n",
      "SubSGD iter. 220/499: loss=2.8121503799146548, w0=75.60000000000015, w1=15.038688920272088\n",
      "SubSGD iter. 221/499: loss=2.8065020379102483, w0=75.60000000000015, w1=12.376724819019456\n",
      "SubSGD iter. 222/499: loss=2.8119302661974785, w0=74.20000000000014, w1=16.58571940154424\n",
      "SubSGD iter. 223/499: loss=2.846748396652681, w0=74.20000000000014, w1=14.320807555325885\n",
      "SubSGD iter. 224/499: loss=2.7848853726756673, w0=77.00000000000016, w1=12.204664214236434\n",
      "SubSGD iter. 225/499: loss=2.926594551454073, w0=74.20000000000014, w1=14.726512611105766\n",
      "SubSGD iter. 226/499: loss=2.853682290859749, w0=71.40000000000013, w1=14.94001317927257\n",
      "SubSGD iter. 227/499: loss=2.877143006592877, w0=72.80000000000014, w1=16.730176535070004\n",
      "SubSGD iter. 228/499: loss=2.8912541652971653, w0=71.40000000000013, w1=15.41828315133241\n",
      "SubSGD iter. 229/499: loss=2.8288338519989797, w0=71.40000000000013, w1=15.452524787026942\n",
      "SubSGD iter. 230/499: loss=2.9074664082168145, w0=74.20000000000014, w1=16.674137902872154\n",
      "SubSGD iter. 231/499: loss=2.7563764379275484, w0=70.00000000000013, w1=16.897853854954928\n",
      "SubSGD iter. 232/499: loss=2.8572287601030406, w0=75.60000000000015, w1=18.78610689579323\n",
      "SubSGD iter. 233/499: loss=2.8571043420897904, w0=71.40000000000013, w1=16.196198925165305\n",
      "SubSGD iter. 234/499: loss=2.8536909251743827, w0=70.00000000000013, w1=16.461640183246505\n",
      "SubSGD iter. 235/499: loss=2.947472518435433, w0=71.40000000000013, w1=14.689844443681034\n",
      "SubSGD iter. 236/499: loss=2.8436294577269288, w0=75.60000000000015, w1=14.282979028121325\n",
      "SubSGD iter. 237/499: loss=2.834016455967043, w0=74.20000000000014, w1=14.330912845480299\n",
      "SubSGD iter. 238/499: loss=2.818314777686421, w0=71.40000000000013, w1=17.238561803257163\n",
      "SubSGD iter. 239/499: loss=2.8875761451835498, w0=72.80000000000014, w1=15.867042476034388\n",
      "SubSGD iter. 240/499: loss=2.902648820318255, w0=71.40000000000013, w1=16.35072059125576\n",
      "SubSGD iter. 241/499: loss=2.856308548330413, w0=71.40000000000013, w1=17.54580301708227\n",
      "SubSGD iter. 242/499: loss=2.9086054332382707, w0=74.20000000000014, w1=17.031162800598743\n",
      "SubSGD iter. 243/499: loss=2.8666255882283815, w0=72.80000000000014, w1=17.322422040148194\n",
      "SubSGD iter. 244/499: loss=2.832985513721575, w0=72.80000000000014, w1=13.816278338624626\n",
      "SubSGD iter. 245/499: loss=2.858334594769598, w0=72.80000000000014, w1=13.608809585892267\n",
      "SubSGD iter. 246/499: loss=2.8525922863962125, w0=72.80000000000014, w1=16.054722716442484\n",
      "SubSGD iter. 247/499: loss=2.8066458906921197, w0=72.80000000000014, w1=16.258305633703067\n",
      "SubSGD iter. 248/499: loss=2.8663610088544287, w0=74.20000000000014, w1=13.418098404803041\n",
      "SubSGD iter. 249/499: loss=2.852407544593771, w0=72.80000000000014, w1=15.606146929496937\n",
      "SubSGD iter. 250/499: loss=2.8874969243806743, w0=74.20000000000014, w1=16.596442621670572\n",
      "SubSGD iter. 251/499: loss=2.769850583376918, w0=75.60000000000015, w1=15.18820893350087\n",
      "SubSGD iter. 252/499: loss=2.9006182901004856, w0=71.40000000000013, w1=14.130413327534548\n",
      "SubSGD iter. 253/499: loss=2.883225019982236, w0=72.80000000000014, w1=15.481276909547407\n",
      "SubSGD iter. 254/499: loss=2.871199459930474, w0=74.20000000000014, w1=15.956804275468786\n",
      "SubSGD iter. 255/499: loss=2.9189792570094073, w0=74.20000000000014, w1=14.088314102865844\n",
      "SubSGD iter. 256/499: loss=2.8505164053677756, w0=74.20000000000014, w1=17.639331838681112\n",
      "SubSGD iter. 257/499: loss=2.861892658039648, w0=72.80000000000014, w1=16.812597837693126\n",
      "SubSGD iter. 258/499: loss=2.9234292142114366, w0=74.20000000000014, w1=15.895461599557072\n",
      "SubSGD iter. 259/499: loss=2.765640486476117, w0=74.20000000000014, w1=15.148246406914607\n",
      "SubSGD iter. 260/499: loss=2.886910983343806, w0=72.80000000000014, w1=16.1196139807443\n",
      "SubSGD iter. 261/499: loss=2.854521158081061, w0=72.80000000000014, w1=15.080833372418471\n",
      "SubSGD iter. 262/499: loss=2.8909571047641918, w0=72.80000000000014, w1=15.800110499329076\n",
      "SubSGD iter. 263/499: loss=2.7679999534203428, w0=75.60000000000015, w1=11.615241117499586\n",
      "SubSGD iter. 264/499: loss=2.887578855419494, w0=72.80000000000014, w1=15.727173555115321\n",
      "SubSGD iter. 265/499: loss=2.9051696048594375, w0=72.80000000000014, w1=15.738342869490564\n",
      "SubSGD iter. 266/499: loss=2.8950295741105934, w0=74.20000000000014, w1=15.198096214728437\n",
      "SubSGD iter. 267/499: loss=2.862828719424597, w0=74.20000000000014, w1=16.350790867911236\n",
      "SubSGD iter. 268/499: loss=2.837047314782539, w0=71.40000000000013, w1=15.845329231599653\n",
      "SubSGD iter. 269/499: loss=2.8207491187730973, w0=75.60000000000015, w1=17.38868643105103\n",
      "SubSGD iter. 270/499: loss=2.8123688178463655, w0=74.20000000000014, w1=16.923028489973795\n",
      "SubSGD iter. 271/499: loss=2.870930397270911, w0=72.80000000000014, w1=16.877138846772848\n",
      "SubSGD iter. 272/499: loss=2.854203579499121, w0=75.60000000000015, w1=16.71969023779738\n",
      "SubSGD iter. 273/499: loss=2.836572447587904, w0=74.20000000000014, w1=16.222703695662478\n",
      "SubSGD iter. 274/499: loss=2.849435862057208, w0=74.20000000000014, w1=14.978150712473195\n",
      "SubSGD iter. 275/499: loss=2.8019083507311997, w0=75.60000000000015, w1=15.08929089862157\n",
      "SubSGD iter. 276/499: loss=2.868541086172511, w0=75.60000000000015, w1=18.013374569931774\n",
      "SubSGD iter. 277/499: loss=2.749359821075774, w0=75.60000000000015, w1=13.328651311766789\n",
      "SubSGD iter. 278/499: loss=2.845667904029296, w0=71.40000000000013, w1=15.539204850745358\n",
      "SubSGD iter. 279/499: loss=2.8452001973041683, w0=72.80000000000014, w1=18.136860517549\n",
      "SubSGD iter. 280/499: loss=2.854680918949209, w0=74.20000000000014, w1=14.871124029176649\n",
      "SubSGD iter. 281/499: loss=2.769564904477697, w0=72.80000000000014, w1=16.268441358840665\n",
      "SubSGD iter. 282/499: loss=2.805993185624781, w0=74.20000000000014, w1=14.366219098626463\n",
      "SubSGD iter. 283/499: loss=2.8048587118260695, w0=71.40000000000013, w1=16.50287450980751\n",
      "SubSGD iter. 284/499: loss=2.8791120527831566, w0=74.20000000000014, w1=16.836604763250783\n",
      "SubSGD iter. 285/499: loss=2.8203984337928114, w0=74.20000000000014, w1=14.411973751728967\n",
      "SubSGD iter. 286/499: loss=2.8242135573557223, w0=72.80000000000014, w1=16.224698472293774\n",
      "SubSGD iter. 287/499: loss=2.880295110824601, w0=74.20000000000014, w1=14.950834223675063\n",
      "SubSGD iter. 288/499: loss=2.771132892273345, w0=74.20000000000014, w1=15.779288930259247\n",
      "SubSGD iter. 289/499: loss=2.6933052140871756, w0=74.20000000000014, w1=10.525190890497896\n",
      "SubSGD iter. 290/499: loss=2.8876612080704387, w0=71.40000000000013, w1=15.160184224685047\n",
      "SubSGD iter. 291/499: loss=2.791058059452767, w0=74.20000000000014, w1=14.155833406148151\n",
      "SubSGD iter. 292/499: loss=2.837075441607546, w0=74.20000000000014, w1=12.841827985987624\n",
      "SubSGD iter. 293/499: loss=2.759108833882794, w0=72.80000000000014, w1=11.716168838202726\n",
      "SubSGD iter. 294/499: loss=2.946773989258795, w0=74.20000000000014, w1=15.189022762203482\n",
      "SubSGD iter. 295/499: loss=2.847768205756733, w0=74.20000000000014, w1=17.62135842205344\n",
      "SubSGD iter. 296/499: loss=2.8918149702980687, w0=72.80000000000014, w1=15.86256087738818\n",
      "SubSGD iter. 297/499: loss=2.8232871273791624, w0=70.00000000000013, w1=17.73267593338057\n",
      "SubSGD iter. 298/499: loss=2.8677309871289993, w0=75.60000000000015, w1=15.982030253743064\n",
      "SubSGD iter. 299/499: loss=2.9119876451738014, w0=72.80000000000014, w1=15.227135835106957\n",
      "SubSGD iter. 300/499: loss=2.860044918597926, w0=71.40000000000013, w1=16.55531199143924\n",
      "SubSGD iter. 301/499: loss=2.8413178302222706, w0=70.00000000000013, w1=17.498361685712972\n",
      "SubSGD iter. 302/499: loss=2.893702358732001, w0=71.40000000000013, w1=17.064289744375934\n",
      "SubSGD iter. 303/499: loss=2.9206985328096007, w0=71.40000000000013, w1=15.960068810283513\n",
      "SubSGD iter. 304/499: loss=2.840446884895469, w0=70.00000000000013, w1=16.906103515323107\n",
      "SubSGD iter. 305/499: loss=2.8657161622628373, w0=71.40000000000013, w1=15.864681286808587\n",
      "SubSGD iter. 306/499: loss=2.9064104986383126, w0=74.20000000000014, w1=15.712927865224126\n",
      "SubSGD iter. 307/499: loss=2.9089907169198956, w0=74.20000000000014, w1=17.53974976656371\n",
      "SubSGD iter. 308/499: loss=2.916150147070212, w0=74.20000000000014, w1=17.49410599276065\n",
      "SubSGD iter. 309/499: loss=2.7904425330568308, w0=78.40000000000016, w1=11.188698609426893\n",
      "SubSGD iter. 310/499: loss=2.9691482894360424, w0=72.80000000000014, w1=16.888713186674146\n",
      "SubSGD iter. 311/499: loss=2.8224930250082685, w0=72.80000000000014, w1=11.771911342838212\n",
      "SubSGD iter. 312/499: loss=2.868827822802367, w0=70.00000000000013, w1=17.279064531452686\n",
      "SubSGD iter. 313/499: loss=2.8702144334764323, w0=72.80000000000014, w1=16.209634517747094\n",
      "SubSGD iter. 314/499: loss=2.8182662129253995, w0=71.40000000000013, w1=18.368360237329853\n",
      "SubSGD iter. 315/499: loss=2.852993514578936, w0=74.20000000000014, w1=14.531596268573885\n",
      "SubSGD iter. 316/499: loss=2.904655093909504, w0=74.20000000000014, w1=13.736224346191525\n",
      "SubSGD iter. 317/499: loss=2.833859107021135, w0=74.20000000000014, w1=16.009166905323383\n",
      "SubSGD iter. 318/499: loss=2.838734377576814, w0=71.40000000000013, w1=13.217039264773314\n",
      "SubSGD iter. 319/499: loss=2.875287144307081, w0=74.20000000000014, w1=17.726024460104217\n",
      "SubSGD iter. 320/499: loss=2.8054215773622224, w0=72.80000000000014, w1=16.737140795785056\n",
      "SubSGD iter. 321/499: loss=2.8400729110267426, w0=72.80000000000014, w1=15.847153526197697\n",
      "SubSGD iter. 322/499: loss=2.8901327033154263, w0=70.00000000000013, w1=15.35443035817734\n",
      "SubSGD iter. 323/499: loss=2.8471369522711165, w0=72.80000000000014, w1=18.486925662201433\n",
      "SubSGD iter. 324/499: loss=2.8556046015258376, w0=74.20000000000014, w1=15.211256240950961\n",
      "SubSGD iter. 325/499: loss=2.7833946294519456, w0=72.80000000000014, w1=15.315568996230084\n",
      "SubSGD iter. 326/499: loss=2.7386446875788044, w0=70.00000000000013, w1=14.835792235741366\n",
      "SubSGD iter. 327/499: loss=2.87646238610364, w0=71.40000000000013, w1=18.529720869618934\n",
      "SubSGD iter. 328/499: loss=2.819771544522454, w0=72.80000000000014, w1=14.598795376406878\n",
      "SubSGD iter. 329/499: loss=2.786373146412566, w0=77.00000000000016, w1=14.10840244204273\n",
      "SubSGD iter. 330/499: loss=2.9122162469727226, w0=70.00000000000013, w1=17.93089818636667\n",
      "SubSGD iter. 331/499: loss=2.8900844105704238, w0=72.80000000000014, w1=16.752740180991946\n",
      "SubSGD iter. 332/499: loss=2.852065078363865, w0=74.20000000000014, w1=16.922496088061877\n",
      "SubSGD iter. 333/499: loss=2.7824574038329244, w0=71.40000000000013, w1=16.805225992221377\n",
      "SubSGD iter. 334/499: loss=2.8398307181832916, w0=74.20000000000014, w1=17.63672595828225\n",
      "SubSGD iter. 335/499: loss=2.8606392690725033, w0=74.20000000000014, w1=16.044731647193064\n",
      "SubSGD iter. 336/499: loss=2.816649040855283, w0=71.40000000000013, w1=17.935152579748525\n",
      "SubSGD iter. 337/499: loss=2.892004565163274, w0=72.80000000000014, w1=14.078459853213065\n",
      "SubSGD iter. 338/499: loss=2.85736219831008, w0=72.80000000000014, w1=19.750019952605772\n",
      "SubSGD iter. 339/499: loss=2.9086101553824535, w0=71.40000000000013, w1=16.253692207325326\n",
      "SubSGD iter. 340/499: loss=2.798171572558385, w0=75.60000000000015, w1=15.268465826171287\n",
      "SubSGD iter. 341/499: loss=2.8761244143550386, w0=71.40000000000013, w1=19.06740314600164\n",
      "SubSGD iter. 342/499: loss=2.8432073453689943, w0=72.80000000000014, w1=17.068587555816677\n",
      "SubSGD iter. 343/499: loss=2.845662449129851, w0=74.20000000000014, w1=17.382421546921474\n",
      "SubSGD iter. 344/499: loss=2.8899138718918977, w0=74.20000000000014, w1=16.39320886015805\n",
      "SubSGD iter. 345/499: loss=2.840645928317549, w0=75.60000000000015, w1=17.16973907009951\n",
      "SubSGD iter. 346/499: loss=2.9007635445465345, w0=71.40000000000013, w1=17.25081136409216\n",
      "SubSGD iter. 347/499: loss=2.8306526700783414, w0=70.00000000000013, w1=15.119569672502202\n",
      "SubSGD iter. 348/499: loss=2.87018610731938, w0=71.40000000000013, w1=14.619015210970728\n",
      "SubSGD iter. 349/499: loss=2.8522533286329823, w0=72.80000000000014, w1=13.581659249000529\n",
      "SubSGD iter. 350/499: loss=2.9010441475716466, w0=74.20000000000014, w1=13.667648590168582\n",
      "SubSGD iter. 351/499: loss=2.9036143872102333, w0=71.40000000000013, w1=15.620866751652706\n",
      "SubSGD iter. 352/499: loss=2.840000018383861, w0=72.80000000000014, w1=16.726658645471986\n",
      "SubSGD iter. 353/499: loss=2.8176651238237587, w0=75.60000000000015, w1=17.487365355990246\n",
      "SubSGD iter. 354/499: loss=2.9484373119498555, w0=71.40000000000013, w1=16.903214274803908\n",
      "SubSGD iter. 355/499: loss=2.901647237092536, w0=71.40000000000013, w1=16.4664990674197\n",
      "SubSGD iter. 356/499: loss=2.7962391870667713, w0=72.80000000000014, w1=16.00598526002073\n",
      "SubSGD iter. 357/499: loss=2.847961795122025, w0=72.80000000000014, w1=15.125544920626718\n",
      "SubSGD iter. 358/499: loss=2.855315326260135, w0=72.80000000000014, w1=15.127548797146575\n",
      "SubSGD iter. 359/499: loss=2.797117353746339, w0=74.20000000000014, w1=12.392280717697382\n",
      "SubSGD iter. 360/499: loss=2.9095839667420833, w0=74.20000000000014, w1=15.871995106392816\n",
      "SubSGD iter. 361/499: loss=2.8464350187824845, w0=71.40000000000013, w1=17.067950752067812\n",
      "SubSGD iter. 362/499: loss=2.8447233883520857, w0=71.40000000000013, w1=15.646490382456227\n",
      "SubSGD iter. 363/499: loss=2.8641626702781156, w0=74.20000000000014, w1=16.257320073183045\n",
      "SubSGD iter. 364/499: loss=2.799440604108648, w0=72.80000000000014, w1=15.237518994382587\n",
      "SubSGD iter. 365/499: loss=2.854033666750782, w0=72.80000000000014, w1=12.681284624626548\n",
      "SubSGD iter. 366/499: loss=2.753310496675474, w0=72.80000000000014, w1=18.29934986401083\n",
      "SubSGD iter. 367/499: loss=2.8631184139054664, w0=75.60000000000015, w1=12.782939457349938\n",
      "SubSGD iter. 368/499: loss=2.9172884519511597, w0=71.40000000000013, w1=16.710921193100923\n",
      "SubSGD iter. 369/499: loss=2.896952539173712, w0=72.80000000000014, w1=17.093319225849555\n",
      "SubSGD iter. 370/499: loss=2.8932428724239263, w0=72.80000000000014, w1=18.01925769763405\n",
      "SubSGD iter. 371/499: loss=2.871188756565986, w0=74.20000000000014, w1=19.81514829927823\n",
      "SubSGD iter. 372/499: loss=2.8884830765754765, w0=74.20000000000014, w1=14.030665467166198\n",
      "SubSGD iter. 373/499: loss=2.857927578546294, w0=72.80000000000014, w1=17.13661927376384\n",
      "SubSGD iter. 374/499: loss=2.842482001557324, w0=71.40000000000013, w1=14.90775209544442\n",
      "SubSGD iter. 375/499: loss=2.7819850451591925, w0=72.80000000000014, w1=17.49061071667809\n",
      "SubSGD iter. 376/499: loss=2.716822835072807, w0=75.60000000000015, w1=15.667424362390713\n",
      "SubSGD iter. 377/499: loss=2.8945844931230886, w0=72.80000000000014, w1=16.71511318029384\n",
      "SubSGD iter. 378/499: loss=2.788815962822248, w0=71.40000000000013, w1=14.497795999712405\n",
      "SubSGD iter. 379/499: loss=2.8423616181726032, w0=72.80000000000014, w1=15.694438977374643\n",
      "SubSGD iter. 380/499: loss=2.8665913586480216, w0=72.80000000000014, w1=18.653507012470996\n",
      "SubSGD iter. 381/499: loss=2.7967569319686083, w0=72.80000000000014, w1=15.480402148970338\n",
      "SubSGD iter. 382/499: loss=2.8726753081513867, w0=71.40000000000013, w1=15.555330041748242\n",
      "SubSGD iter. 383/499: loss=2.8942034677489015, w0=71.40000000000013, w1=13.744216248904001\n",
      "SubSGD iter. 384/499: loss=2.9085086838232654, w0=72.80000000000014, w1=14.757327443599301\n",
      "SubSGD iter. 385/499: loss=2.859325062478121, w0=74.20000000000014, w1=15.98769382109045\n",
      "SubSGD iter. 386/499: loss=2.9173353217745595, w0=74.20000000000014, w1=13.361086859549093\n",
      "SubSGD iter. 387/499: loss=2.9221797292957072, w0=72.80000000000014, w1=13.846687107884195\n",
      "SubSGD iter. 388/499: loss=2.970260455095382, w0=71.40000000000013, w1=16.905722278026683\n",
      "SubSGD iter. 389/499: loss=2.8334359203073562, w0=77.00000000000016, w1=17.737073536461534\n",
      "SubSGD iter. 390/499: loss=2.902008417450003, w0=72.80000000000014, w1=14.929094126485253\n",
      "SubSGD iter. 391/499: loss=2.873246614996817, w0=72.80000000000014, w1=16.633716263970292\n",
      "SubSGD iter. 392/499: loss=2.843745510945628, w0=74.20000000000014, w1=16.00690733861194\n",
      "SubSGD iter. 393/499: loss=2.854620371557854, w0=75.60000000000015, w1=16.520808753171735\n",
      "SubSGD iter. 394/499: loss=2.908523934301023, w0=72.80000000000014, w1=15.756051429659857\n",
      "SubSGD iter. 395/499: loss=2.808421840579428, w0=72.80000000000014, w1=19.122813760373408\n",
      "SubSGD iter. 396/499: loss=2.8993460762913617, w0=75.60000000000015, w1=16.108277731621786\n",
      "SubSGD iter. 397/499: loss=2.8740086279801433, w0=74.20000000000014, w1=14.036991583848279\n",
      "SubSGD iter. 398/499: loss=2.7783003490071176, w0=72.80000000000014, w1=12.202842999897982\n",
      "SubSGD iter. 399/499: loss=2.754334670363449, w0=71.40000000000013, w1=16.98959667973366\n",
      "SubSGD iter. 400/499: loss=2.9047115446860383, w0=72.80000000000014, w1=14.300299000356514\n",
      "SubSGD iter. 401/499: loss=2.9118365499524907, w0=74.20000000000014, w1=14.068366705002772\n",
      "SubSGD iter. 402/499: loss=2.932848807396759, w0=72.80000000000014, w1=16.305428465611733\n",
      "SubSGD iter. 403/499: loss=2.8578682975156364, w0=71.40000000000013, w1=16.732555362272986\n",
      "SubSGD iter. 404/499: loss=2.8760654855957175, w0=74.20000000000014, w1=17.469883600587618\n",
      "SubSGD iter. 405/499: loss=2.855925638294095, w0=71.40000000000013, w1=14.69192925997465\n",
      "SubSGD iter. 406/499: loss=2.8664811451211305, w0=72.80000000000014, w1=16.483619968979614\n",
      "SubSGD iter. 407/499: loss=2.867902656298483, w0=75.60000000000015, w1=16.24405604045173\n",
      "SubSGD iter. 408/499: loss=2.8782543440286563, w0=72.80000000000014, w1=16.642817960745585\n",
      "SubSGD iter. 409/499: loss=2.8485152831268827, w0=74.20000000000014, w1=12.785853906718444\n",
      "SubSGD iter. 410/499: loss=2.8888588901151784, w0=71.40000000000013, w1=17.364833699286635\n",
      "SubSGD iter. 411/499: loss=2.8768404933004446, w0=70.00000000000013, w1=13.768293936698871\n",
      "SubSGD iter. 412/499: loss=2.8463011195947945, w0=72.80000000000014, w1=12.606357599253528\n",
      "SubSGD iter. 413/499: loss=2.8040733742401285, w0=71.40000000000013, w1=16.086990398339996\n",
      "SubSGD iter. 414/499: loss=2.8409884669513445, w0=71.40000000000013, w1=19.19834665721513\n",
      "SubSGD iter. 415/499: loss=2.8286203705342294, w0=71.40000000000013, w1=15.425522276378691\n",
      "SubSGD iter. 416/499: loss=2.855083159081954, w0=72.80000000000014, w1=15.477486603448662\n",
      "SubSGD iter. 417/499: loss=2.7816704830612546, w0=72.80000000000014, w1=18.80212378307416\n",
      "SubSGD iter. 418/499: loss=2.784752127215776, w0=74.20000000000014, w1=15.777857085542133\n",
      "SubSGD iter. 419/499: loss=2.902547645584183, w0=74.20000000000014, w1=16.968430382232008\n",
      "SubSGD iter. 420/499: loss=2.8834018815042883, w0=72.80000000000014, w1=15.733902953143103\n",
      "SubSGD iter. 421/499: loss=2.8716854399856446, w0=71.40000000000013, w1=15.521746484696875\n",
      "SubSGD iter. 422/499: loss=2.8655206202276537, w0=75.60000000000015, w1=15.314038261044265\n",
      "SubSGD iter. 423/499: loss=2.8523253234724915, w0=72.80000000000014, w1=13.984978032782816\n",
      "SubSGD iter. 424/499: loss=2.843519470073597, w0=72.80000000000014, w1=18.062460477629354\n",
      "SubSGD iter. 425/499: loss=2.829093186034461, w0=70.00000000000013, w1=17.00272235899605\n",
      "SubSGD iter. 426/499: loss=2.8665222819145044, w0=74.20000000000014, w1=11.308570648390866\n",
      "SubSGD iter. 427/499: loss=2.811928764726564, w0=72.80000000000014, w1=18.73538403178691\n",
      "SubSGD iter. 428/499: loss=2.840171138259326, w0=72.80000000000014, w1=15.396280453085186\n",
      "SubSGD iter. 429/499: loss=2.8770729781822046, w0=70.00000000000013, w1=16.41529397192751\n",
      "SubSGD iter. 430/499: loss=2.841033230794043, w0=72.80000000000014, w1=15.0966854628123\n",
      "SubSGD iter. 431/499: loss=2.8306281273974, w0=72.80000000000014, w1=13.221395204413664\n",
      "SubSGD iter. 432/499: loss=2.8222273349512976, w0=68.60000000000012, w1=16.363457896811028\n",
      "SubSGD iter. 433/499: loss=2.866919293107068, w0=72.80000000000014, w1=16.979616136425378\n",
      "SubSGD iter. 434/499: loss=2.8515665219893025, w0=74.20000000000014, w1=17.072771040668773\n",
      "SubSGD iter. 435/499: loss=2.7938135507125437, w0=74.20000000000014, w1=10.310563712308674\n",
      "SubSGD iter. 436/499: loss=2.89659990297841, w0=71.40000000000013, w1=19.071026092435993\n",
      "SubSGD iter. 437/499: loss=2.9075831985607565, w0=75.60000000000015, w1=13.726747472876403\n",
      "SubSGD iter. 438/499: loss=2.8828752708310055, w0=71.40000000000013, w1=15.387589410189207\n",
      "SubSGD iter. 439/499: loss=2.9256660666882373, w0=72.80000000000014, w1=17.5448226501159\n",
      "SubSGD iter. 440/499: loss=2.745264159285121, w0=74.20000000000014, w1=16.861655454697388\n",
      "SubSGD iter. 441/499: loss=2.8077472356067137, w0=72.80000000000014, w1=15.36567769254039\n",
      "SubSGD iter. 442/499: loss=2.8314244027982385, w0=72.80000000000014, w1=16.163851714293383\n",
      "SubSGD iter. 443/499: loss=2.898184177720699, w0=74.20000000000014, w1=15.61868247955069\n",
      "SubSGD iter. 444/499: loss=2.8838151072255167, w0=72.80000000000014, w1=17.188436399494375\n",
      "SubSGD iter. 445/499: loss=2.8608239378577274, w0=74.20000000000014, w1=14.09315686456803\n",
      "SubSGD iter. 446/499: loss=2.85526646150453, w0=71.40000000000013, w1=13.996202754407818\n",
      "SubSGD iter. 447/499: loss=2.808589684747691, w0=77.00000000000016, w1=18.708530079719733\n",
      "SubSGD iter. 448/499: loss=2.8515077904499653, w0=74.20000000000014, w1=14.535721613551962\n",
      "SubSGD iter. 449/499: loss=2.8437704696890482, w0=72.80000000000014, w1=13.596524781695482\n",
      "SubSGD iter. 450/499: loss=2.7961471142888774, w0=74.20000000000014, w1=12.913068205149104\n",
      "SubSGD iter. 451/499: loss=2.734437709821915, w0=74.20000000000014, w1=20.460393257319335\n",
      "SubSGD iter. 452/499: loss=2.873712437533042, w0=72.80000000000014, w1=14.564651139302693\n",
      "SubSGD iter. 453/499: loss=2.8692670393142183, w0=72.80000000000014, w1=13.577248679707653\n",
      "SubSGD iter. 454/499: loss=2.808332852901329, w0=75.60000000000015, w1=16.81393234196769\n",
      "SubSGD iter. 455/499: loss=2.8942339769539815, w0=71.40000000000013, w1=14.887710828172855\n",
      "SubSGD iter. 456/499: loss=2.928789792916085, w0=71.40000000000013, w1=17.986490383601993\n",
      "SubSGD iter. 457/499: loss=2.860159133637782, w0=70.00000000000013, w1=19.531124681777715\n",
      "SubSGD iter. 458/499: loss=2.855245092680579, w0=75.60000000000015, w1=14.236952229435998\n",
      "SubSGD iter. 459/499: loss=2.8419288962498035, w0=72.80000000000014, w1=19.45394285963963\n",
      "SubSGD iter. 460/499: loss=2.9204893409425368, w0=71.40000000000013, w1=15.931818256495887\n",
      "SubSGD iter. 461/499: loss=2.822822010630905, w0=72.80000000000014, w1=16.329400761501056\n",
      "SubSGD iter. 462/499: loss=2.825553254927379, w0=72.80000000000014, w1=17.52810926257015\n",
      "SubSGD iter. 463/499: loss=2.773075850040219, w0=72.80000000000014, w1=15.100688298300751\n",
      "SubSGD iter. 464/499: loss=2.8234495818947574, w0=74.20000000000014, w1=15.323303556178725\n",
      "SubSGD iter. 465/499: loss=2.86397164646469, w0=71.40000000000013, w1=17.99227790708929\n",
      "SubSGD iter. 466/499: loss=2.940814618831176, w0=71.40000000000013, w1=15.52791525509375\n",
      "SubSGD iter. 467/499: loss=2.889358210959737, w0=71.40000000000013, w1=15.354387602985494\n",
      "SubSGD iter. 468/499: loss=2.827713428165459, w0=75.60000000000015, w1=14.387463168498762\n",
      "SubSGD iter. 469/499: loss=2.879039279239908, w0=72.80000000000014, w1=14.451115967438593\n",
      "SubSGD iter. 470/499: loss=2.818012761148473, w0=72.80000000000014, w1=17.216028330514334\n",
      "SubSGD iter. 471/499: loss=2.7997403604815565, w0=72.80000000000014, w1=14.901252933059187\n",
      "SubSGD iter. 472/499: loss=2.9293293676031937, w0=71.40000000000013, w1=16.82484072483599\n",
      "SubSGD iter. 473/499: loss=2.8789574558838655, w0=74.20000000000014, w1=10.877848810004787\n",
      "SubSGD iter. 474/499: loss=2.914913792503721, w0=71.40000000000013, w1=15.812190621108233\n",
      "SubSGD iter. 475/499: loss=2.8514696936777435, w0=71.40000000000013, w1=18.33554339825329\n",
      "SubSGD iter. 476/499: loss=2.860423360032317, w0=72.80000000000014, w1=16.27530777752005\n",
      "SubSGD iter. 477/499: loss=2.8305430697655534, w0=75.60000000000015, w1=13.970520790171804\n",
      "SubSGD iter. 478/499: loss=2.805260884551305, w0=75.60000000000015, w1=14.378757810720638\n",
      "SubSGD iter. 479/499: loss=2.8137447747283244, w0=70.00000000000013, w1=15.550163431343707\n",
      "SubSGD iter. 480/499: loss=2.8646361357694987, w0=70.00000000000013, w1=17.220635513106508\n",
      "SubSGD iter. 481/499: loss=2.871875617406104, w0=72.80000000000014, w1=13.75304896881156\n",
      "SubSGD iter. 482/499: loss=2.8682834706934774, w0=70.00000000000013, w1=18.926042303505056\n",
      "SubSGD iter. 483/499: loss=2.900721008133949, w0=74.20000000000014, w1=15.257541486383403\n",
      "SubSGD iter. 484/499: loss=2.8531968088404582, w0=72.80000000000014, w1=16.56600992851415\n",
      "SubSGD iter. 485/499: loss=2.8319414377758663, w0=74.20000000000014, w1=14.625889134767228\n",
      "SubSGD iter. 486/499: loss=2.9164191457586335, w0=71.40000000000013, w1=14.765915253547284\n",
      "SubSGD iter. 487/499: loss=2.891250623041387, w0=72.80000000000014, w1=15.451606710840476\n",
      "SubSGD iter. 488/499: loss=2.9219742914764653, w0=72.80000000000014, w1=14.445821696949869\n",
      "SubSGD iter. 489/499: loss=2.8859425446214324, w0=72.80000000000014, w1=14.755725221845328\n",
      "SubSGD iter. 490/499: loss=2.891011856545941, w0=72.80000000000014, w1=14.517571003629252\n",
      "SubSGD iter. 491/499: loss=2.8382187869557622, w0=74.20000000000014, w1=15.256978301193563\n",
      "SubSGD iter. 492/499: loss=2.8523305909061603, w0=74.20000000000014, w1=17.034812965615654\n",
      "SubSGD iter. 493/499: loss=2.787449469423239, w0=71.40000000000013, w1=20.480691154179528\n",
      "SubSGD iter. 494/499: loss=2.9055699117558467, w0=72.80000000000014, w1=14.753671242036972\n",
      "SubSGD iter. 495/499: loss=2.898092999909959, w0=74.20000000000014, w1=15.642217467959753\n",
      "SubSGD iter. 496/499: loss=2.885045490737818, w0=70.00000000000013, w1=14.335737040375841\n",
      "SubSGD iter. 497/499: loss=2.77146644902351, w0=70.00000000000013, w1=16.19908542627699\n",
      "SubSGD iter. 498/499: loss=2.9230544821263074, w0=74.20000000000014, w1=16.523635717867474\n",
      "SubSGD iter. 499/499: loss=2.8274419361019136, w0=71.40000000000013, w1=17.462557742751553\n",
      "SubSGD: execution time=1.951 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd79d3d12a949dbad923082c9fd6a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
